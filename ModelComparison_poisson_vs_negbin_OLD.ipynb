{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "\n",
    "from random import shuffle\n",
    "from scipy.stats import gamma, beta, nbinom, poisson\n",
    "from scipy.special import gammaln, betaln\n",
    "from torch.autograd import Variable\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "mpl.rcParams['axes.titlesize'] = 20\n",
    "mpl.rcParams['axes.labelsize'] = 17\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['legend.fontsize'] = 16\n",
    "mpl.rcParams['figure.figsize'] = (15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Poisson data, compare Poisson vs. negBin model\n",
    "\n",
    "I will train a MDN to approximate the posterior over model indices. As models I use a Poisson with Gamma prior and a negative Binomial with Beta prior. To this end I will generate a large data set of samples from either Poisson or NB with hyperparameters sampled from the priors. This data set I will use to train the MDN. Finally I will generate test data from either Poisson or NB with hyperparameters chosen as the mean of the corresponding prior. Given the test data the analytical Bayes factor and the Bayes factor predicted by the model is compared. \n",
    "\n",
    "### Controlling difficulty via over / under dispersion \n",
    "Overdispersion means that the dispersion predicted by the model is less than that present in the data. Here we can control the difficulty of distinguishing between the two models by changing the dispersion of the observed data and by making use of the fact that while in the Poisson model the mean equals the variance, in the NB model we have an additional DoF for the variance. \n",
    "\n",
    "Given that we want to start with a very simple case, we should choose the Gamma and Beta priors on the Poisson and the NB model such that they result in very different data models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "n_samples = 10000\n",
    "\n",
    "difficult = False\n",
    "diff_string = 'diff' if difficult else 'easy'\n",
    "\n",
    "time_stamp = time.strftime('%Y%m%d%H%M_')\n",
    "\n",
    "# set prior parameters \n",
    "# gamma prior shape and scale x\n",
    "shape = 9. if difficult else 7.5\n",
    "scale = 0.5 if difficult else 1.0 \n",
    "# create a frozen distribution object\n",
    "gamma_prior = gamma(a=shape, scale=scale)\n",
    "\n",
    "# beta prior shape and scale \n",
    "alp = 2. if difficult else 5.0 \n",
    "bet = 5. if difficult else 2.0 \n",
    "# neg bin number of successes, fixed\n",
    "r = 3.\n",
    "beta_prior = beta(a=alp, b=bet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_figure(filename, folder='figures'):\n",
    "    plt.savefig(os.path.join('figures', time_stamp + filename + '.png'), dpi=300)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(50)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(211)\n",
    "for i in range(20): \n",
    "    priorNB = nbinom.pmf(k, r, beta_prior.rvs())\n",
    "    priorP = poisson.pmf(k, gamma_prior.rvs())\n",
    "    \n",
    "    plt.plot(k, priorNB, 'C0')\n",
    "    plt.plot(k, priorP, 'C1')\n",
    "    \n",
    "plt.title('Example model PMFs given samples from the priors')\n",
    "plt.legend(['NB model', 'Poisson model'])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(k, nbinom.pmf(k, r, beta_prior.mean()), 'C0')\n",
    "plt.plot(k, poisson.pmf(k, gamma_prior.mean()), 'C1')\n",
    "plt.title('PMFs used to generate the test data')\n",
    "plt.legend(['NB', 'Poisson'])\n",
    "\n",
    "save_figure(filename='data_pmfs_' + diff_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for generating data from the two different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_stats(x):\n",
    "    return np.array([np.sum(x).astype(float)])\n",
    "\n",
    "def generate_dataset(n_samples, sample_size): \n",
    "    \n",
    "    X = []\n",
    "    thetas = []\n",
    "    m = []\n",
    "\n",
    "    # for every sample we want a triplet (m_i, theta, sx)\n",
    "    for i in range(n_samples): \n",
    "        \n",
    "        # sample model index \n",
    "        m_i = np.round(np.random.rand()).astype(int)\n",
    "    \n",
    "        # generate data from model \n",
    "        if m_i == 0: \n",
    "            theta, x = generate_poisson(sample_size, gamma_prior)\n",
    "        elif m_i == 1: \n",
    "            theta, x = generate_negbin(sample_size, r, beta_prior)\n",
    "            \n",
    "        sx = calculate_stats(x)\n",
    "            \n",
    "        X.append(sx)\n",
    "        thetas.append([theta])\n",
    "        m.append([int(m_i)])\n",
    "    \n",
    "    return m, np.array(thetas), np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network for fitting the model posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MDN_psi(nn.Module):\n",
    "    \n",
    "    def __init__(self, ndim_input=1, ndim_output=2, n_hidden=5, n_components=1):\n",
    "        super(MDN_psi, self).__init__()\n",
    "        self.fc_in = nn.Linear(ndim_input, n_hidden)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.m_out = nn.Linear(n_hidden, ndim_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc_in(x)\n",
    "        act = self.tanh(out)\n",
    "        out_m = self.m_out(act)\n",
    "        return out_m\n",
    "    \n",
    "def train_psi(X, Y, model, optim, lossfun, n_epochs=500, n_minibatch=50):\n",
    "    dataset_train = [(x, y) for x, y in zip(X, Y)]\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(n_epochs): \n",
    "        bgen = batch_generator(dataset_train, n_minibatch)\n",
    "\n",
    "        for j, (x_batch, y_batch) in enumerate(bgen):\n",
    "            x_var = Variable(torch.Tensor(x_batch))            \n",
    "            y_var = Variable(torch.LongTensor(y_batch)).view(n_minibatch)\n",
    "            \n",
    "            (out_act) = model(x_var)\n",
    "            loss = lossfun(out_act, y_var)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            losses.append(loss.data[0])\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(\"[epoch %04d] loss: %.4f\" % (epoch + 1, loss.data[0]))\n",
    "    \n",
    "    return model, optim, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a large data set of triplets (m, theta, sx)\n",
    "\n",
    "Then separate it into sets for model 1 and model 2 and train the phi networks separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data \n",
    "m, theta, X = generate_dataset(n_samples, sample_size)\n",
    "\n",
    "# normalize \n",
    "X, norm = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 1\n",
    "model = MDN_psi(ndim_input=n_inputs, n_hidden=10)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "model_psi, optim_psi, losses = train_psi(X, m, model, optim, lossfun, n_epochs=500, n_minibatch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw many samples and compare predicted to analytical Bayes Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_true = []\n",
    "bf_predicted = []\n",
    "model_indices = []\n",
    "pred_mi = []\n",
    "prob_poisson = []\n",
    "\n",
    "# gather summary stats\n",
    "stats = []\n",
    "\n",
    "# set the parameters of the underlying model as the means of the corresponding priors\n",
    "poi_mean = gamma_prior.mean()\n",
    "nb_psuccess = beta_prior.mean()\n",
    "\n",
    "# flag for plotting sample distributions\n",
    "plot = False\n",
    "\n",
    "Ntest = 50\n",
    "\n",
    "np.random.seed(1)\n",
    "for i in range(Ntest): \n",
    "    \n",
    "    # sample model index \n",
    "    m_i = np.round(np.random.rand()).astype(int)\n",
    "    \n",
    "    # draw samples from the model given by the model index \n",
    "    if m_i == 0: \n",
    "        samples = poisson.rvs(mu=poi_mean, size=sample_size)\n",
    "    elif m_i == 1: \n",
    "        samples = nbinom.rvs(n=r, p=nb_psuccess, size=sample_size)\n",
    "            \n",
    "    if plot: \n",
    "        plt.subplot(1, 2, m_i + 1)\n",
    "        plt.title('NB' if m_i else 'Poisson')\n",
    "        plt.hist(samples, bins='auto', alpha=.5)\n",
    "    \n",
    "    # apply model for prediction\n",
    "    stats_o = np.array(calculate_stats(samples)).reshape(1, n_inputs)\n",
    "    stats_o, norm = normalize(stats_o, norm)\n",
    "        \n",
    "    stats.append(stats_o)\n",
    "    \n",
    "    X_var = Variable(torch.Tensor(stats_o))\n",
    "    (out_act) = model(X_var)\n",
    "    \n",
    "    # in this vector, index 0 is Poi, index 1 is NB\n",
    "    posterior_probs = nn.Softmax()(out_act).data.numpy()[0]\n",
    "    prob_poisson.append(posterior_probs[0])\n",
    "    \n",
    "    # predict the model with the larger posterior \n",
    "    pred_mi.append(np.argmax(posterior_probs))\n",
    "    \n",
    "    # because we use a uniform prior the posterior ratio corresponds to the likelihood (evidence) ratio\n",
    "    e0 = poisson_sum_evidence(samples, shape, scale, log=True)\n",
    "    e1 = nbin_sum_evidence(samples, alp, bet, r, log=True)\n",
    "\n",
    "    # calculate bf\n",
    "    log_bftrue = e0 - e1\n",
    "    bfpred = posterior_probs[0] / posterior_probs[1]\n",
    "    \n",
    "    # append to lists\n",
    "    bf_predicted.append(np.log(bfpred))\n",
    "    bf_true.append(log_bftrue)\n",
    "    model_indices.append(m_i)\n",
    "    \n",
    "# true indices \n",
    "mi_true = np.array(model_indices)\n",
    "\n",
    "# MAP estimate of model index \n",
    "mi_pred = (np.array(bf_predicted) < 0)  # np.array(pred_mi)\n",
    "\n",
    "# predict m_i = 1 if log BF negaive, m_i = 0 if it is positive\n",
    "mi_ana = (np.array(bf_true) < 0)\n",
    "\n",
    "stats = np.array(stats).reshape(Ntest, n_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the input output function of the network: p(model=Poisson) = f(sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_range = np.linspace(-1., 1., 1000)\n",
    "probs = []\n",
    "for st in stats_range: \n",
    "    (out_act) = model(Variable(torch.Tensor([[st]])))\n",
    "        \n",
    "    # in this vector, index 0 is Poi, index 1 is NB\n",
    "    probs.append(nn.Softmax()(out_act).data.numpy()[0][0])\n",
    "        \n",
    "plt.plot(stats_range, np.array(probs), label='p(poisson)')\n",
    "plt.plot(stats_range, 1 - np.array(probs), label='p(neg bin)')\n",
    "plt.ylabel('P(model)')\n",
    "plt.xlabel('sum(X) normalized')\n",
    "plt.title('Network visualization: p(model) = f(sx)')\n",
    "plt.legend();\n",
    "\n",
    "plt.tight_layout()\n",
    "save_figure(filename='network_visualization_{}'.format(diff_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting summary stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('sufficient statistics')\n",
    "plt.hist(stats[mi_true.astype(int)==0, 0], bins='auto', label='Poisson', alpha=.5)\n",
    "plt.hist(stats[mi_true.astype(int)==1, 0], bins='auto', label='NB', alpha=.5)\n",
    "plt.xlabel(r'Sufficient statistics: x or $\\Sigma x$')\n",
    "plt.legend();\n",
    "save_figure(filename='stats_hists_' + diff_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_predicted = np.array(bf_predicted)\n",
    "bf_true = np.array(bf_true)\n",
    "#plt.figure(figsize=(15, 10))\n",
    "plt.subplot(121)\n",
    "plt.title('Distributions of Bayes factors, MDN prediction')\n",
    "plt.hist(bf_predicted[mi_true.astype(int)==0], bins='auto', alpha=0.5, label='m0')\n",
    "plt.hist(bf_predicted[mi_true.astype(int)==1], bins='auto', alpha=0.5, label='m1');\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.title('analytical')\n",
    "plt.hist(bf_true[mi_true.astype(int)==0], bins='auto', alpha=0.5, label='m0')\n",
    "plt.hist(bf_true[mi_true.astype(int)==1], bins='auto', alpha=0.5, label='m1')\n",
    "plt.legend()\n",
    "plt.savefig('figures/bf_distributions.png', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds = np.linspace(-30, 30, 1000)\n",
    "tpr_mdn = []\n",
    "fpr_mdn = []\n",
    "tpr_ana = []\n",
    "fpr_ana = []\n",
    "\n",
    "m0_mask = mi_true.astype(int)==0\n",
    "m1_mask = mi_true.astype(int)==1\n",
    "\n",
    "def get_rate(th, arr): \n",
    "    count = (arr >= th).sum()\n",
    "    rate = count / arr.size\n",
    "    \n",
    "    return rate\n",
    "\n",
    "for th in thresholds: \n",
    "    \n",
    "    # tpr is the integral of the m0 distribution \n",
    "    tpr_mdn.append(get_rate(th, bf_predicted[m0_mask]))\n",
    "    tpr_ana.append(get_rate(th, bf_true[m0_mask]))\n",
    "    \n",
    "    # fpr is the integral of the m1 distribution \n",
    "    fpr_mdn.append(get_rate(th, bf_predicted[m1_mask]))\n",
    "    fpr_ana.append(get_rate(th, bf_true[m1_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('Bayes factor ROC curves')\n",
    "plt.ylabel('P(TP)')\n",
    "plt.xlabel('P(FP)')\n",
    "plt.plot(fpr_mdn, tpr_mdn, lw=3., alpha=.7, label='MDN')\n",
    "plt.plot(fpr_ana, tpr_ana, '--', label='analytical')\n",
    "plt.plot(fpr_ana, fpr_ana, '-.')\n",
    "plt.legend()\n",
    "save_figure(filename='bf_roc_' + diff_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the array to ascending BF \n",
    "sort_idx = np.argsort(bf_true)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(211)\n",
    "plt.plot(bf_true[sort_idx], bf_predicted[sort_idx], 'o-', label='analytical vs. predicted log BF')\n",
    "plt.plot(bf_true, bf_true, color='k', alpha=0.4)\n",
    "plt.ylabel('predicted log BF')\n",
    "#plt.xlabel('analytical BF')\n",
    "#plt.grid()\n",
    "plt.title('Analytical vs. predicted Bayes factor')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.yticks([0, 1], ['model 0', 'model 1'])\n",
    "plt.plot(bf_true[sort_idx], mi_ana[sort_idx], 'v', markersize=12, label='analytical')\n",
    "plt.plot(bf_true[sort_idx], mi_pred[sort_idx], '^', markersize=12, label='predicted')\n",
    "plt.plot(bf_true[sort_idx], mi_true[sort_idx], 'o', markersize=6, label='ground truth')\n",
    "plt.xlabel('log Bayes factor')\n",
    "plt.ylabel('decision')\n",
    "plt.title('Bayes factor vs. model selection decision')\n",
    "#plt.ylim([-.5, 1.2])\n",
    "plt.grid()\n",
    "plt.legend();\n",
    "plt.tight_layout()\n",
    "\n",
    "#save_figure(filename='bf_decison_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "plt.plot(bf_true[sort_idx], '-o', label='analytical')\n",
    "plt.ylabel('log Bayes factor, analytical')\n",
    "\n",
    "#plt.twinx()\n",
    "plt.plot(bf_predicted[sort_idx], 'o-', label='predicted')\n",
    "plt.ylabel('log Bayes factor')\n",
    "plt.xlabel('different test sets, sorted wrt ascending log(BF)')\n",
    "plt.title('Analytical vs. predicted log Bayes factor')\n",
    "plt.plot(np.zeros(Ntest), '--', label='threshold', color='k')\n",
    "\n",
    "#plt.legend(loc='best')\n",
    "plt.grid()\n",
    "#plt.ylim([-2, 2])\n",
    "\n",
    "plt.twinx()\n",
    "plt.yticks([0, 1], ['model 2', 'model 1'])\n",
    "\n",
    "plt.plot(mi_ana[sort_idx]==0, 'v', markersize=12, label='analytical')\n",
    "plt.plot(mi_pred[sort_idx]==0, '^', markersize=12, label='predicted')\n",
    "plt.plot(mi_true[sort_idx]==0, '*', markersize=8, label='ground truth', color='k')\n",
    "plt.legend(loc=4)\n",
    "plt.ylabel('predicted model')\n",
    "\n",
    "save_figure(filename='bf_evaluation_N{}M{}_{}'.format(n_samples, sample_size, diff_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(bf_true, bf_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(mi_true, 'o-', label='correct model', alpha=1., markersize=7, lw=3)\n",
    "plt.plot(mi_ana, 'x--', label='pred model analytical', alpha=1.)\n",
    "plt.plot(mi_pred, 'o-', label='pred model PSI', alpha=.7)\n",
    "plt.title('True vs. analytical vs. predicted model indices')\n",
    "\n",
    "plt.legend();\n",
    "#plt.savefig(os.path.join('figures', 'mi_prediciton.png'), dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
