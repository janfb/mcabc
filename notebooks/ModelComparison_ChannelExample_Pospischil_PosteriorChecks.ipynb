{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os \n",
    "import pickle\n",
    "import sys \n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "from delfi.utils.viz import plot_pdf\n",
    "from delfi.generator import Default\n",
    "\n",
    "from lfimodels.channelomics.ChannelSingle import ChannelSingle\n",
    "from lfimodels.channelomics.ChannelStats import ChannelStats\n",
    "\n",
    "sys.path.append('../../')\n",
    "from model_comparison.utils import *\n",
    "from model_comparison.mdns import *\n",
    "from model_comparison.models import PoissonModel, NegativeBinomialModel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl_params = {'legend.fontsize': 16,\n",
    "              'legend.frameon': False,\n",
    "                      'axes.titlesize': 20,\n",
    "                      'axes.labelsize': 18,\n",
    "                      'xtick.labelsize': 14,\n",
    "                      'ytick.labelsize': 14,\n",
    "             'figure.figsize' : (18, 5)}\n",
    "\n",
    "mpl.rcParams.update(mpl_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = '../data/'\n",
    "fn = '201804191030__learned_posteriors_pospischil_ntrain192962_kd_nc2.p'\n",
    "time_stamp = fn[:fn.find('_')]\n",
    "\n",
    "with open(os.path.join(folder, fn), 'rb') as f: \n",
    "    d = pickle.load(f)\n",
    "    \n",
    "mi_post_dict = d['model_idx_posterior']\n",
    "p_post_dict = d['parameter_posterior']\n",
    "\n",
    "# set the seed for generating new test data \n",
    "seed = 3\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model index posterior \n",
    "\n",
    "### prior check\n",
    "generate test data different priors on the models: $p(model) = 0.1, ..., 0.9$. Then predict the test set and check whether the average posterior prob of the model corresponds to the prior prob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sx_train, sx_test, mtrain, mtest, data_norm, sx_obs, model_idx_mdn, prior_lims_kd, prior_lims_ks = mi_post_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1000 test samples for each model. Take 100 from $m1$ and 900 from $m2$, then $(200, 800)$, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_probs = np.arange(0.1, 1., 0.1)\n",
    "post_probs_mean = np.zeros_like(prior_probs)\n",
    "sx_test_m1 = sx_test[:1000, ]\n",
    "sx_test_m2 = sx_test[1000:, ]\n",
    "\n",
    "for ii, pp in enumerate(prior_probs): \n",
    "    idx = int(pp * 1000)\n",
    "    # up to idx for m1\n",
    "    d1 = sx_test_m1[:idx, ]\n",
    "    # from idx to end for m2\n",
    "    d2 = sx_test_m2[idx:, ]\n",
    "    test_data = np.vstack((d1, d2))\n",
    "    test_m = np.hstack((np.zeros(idx), np.ones(1000 - idx))).astype(int).tolist()\n",
    "    \n",
    "    # predict \n",
    "    test_data_zt, _ = normalize(test_data, data_norm)\n",
    "    p = model_idx_mdn.predict(test_data_zt)[:, 0]\n",
    "    post_probs_mean[ii] = p.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.plot(prior_probs, post_probs_mean, '-o', label='predictions')\n",
    "ax.plot(prior_probs, prior_probs, label='identity')\n",
    "ax.set_ylabel(r'mean $p(M_{K_{d}} | s(x_o))$')\n",
    "ax.set_xlabel(r'prior $p(M_{K_{d}})$')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = time_stamp + '_channelexample_priorchecks_ntrain{}.png'.format(int(sx_train.shape[0]))\n",
    "fig.savefig(os.path.join('../figures', fn), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to rejection sampling and smc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = '201805040640__modelposterior_comparison_channels_ntest100.p'\n",
    "\n",
    "with open(os.path.join(folder, fn), 'rb') as f: \n",
    "    d = pickle.load(f)\n",
    "    \n",
    "fn = '201805102157__modelposterior_comparison_rejection_sampling_channels_ntest1000_with_priorcheck.p'\n",
    "\n",
    "with open(os.path.join(folder, fn), 'rb') as f: \n",
    "    drej = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtest = np.array(d['mtest'])\n",
    "ppoi_hat = d['ppoi_hat']\n",
    "ppoi_smc = d['ppoi_smc']\n",
    "n_simulations = d['n_simulations']\n",
    "ppoi_smc[ppoi_smc == 0.] = 1e-9\n",
    "ppoi_smc[ppoi_smc == 1.] = 1 - 1e-9\n",
    "\n",
    "cel_de = cross_entropy_loss(mtest, 1 - ppoi_hat)\n",
    "cel_smc = cross_entropy_loss(1 - np.array(mtest), ppoi_smc.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtest = drej['mtest']\n",
    "ppoi_hat = drej['ppoi_hat']\n",
    "# idx=4 to get the uniform prior case. \n",
    "ppoi_rej = drej['ppoi_rej'][4,]\n",
    "ppoi_rej[ppoi_rej == 0.] = 1e-9\n",
    "ppoi_rej[ppoi_rej == 1.] = 1 - 1e-9\n",
    "# take mean over test samples \n",
    "post_probs_mean_rej = np.nanmean(drej['ppoi_rej'], axis=1)\n",
    "\n",
    "cel_de = cross_entropy_loss(np.array(mtest), 1 - ppoi_hat)\n",
    "cel_rej = cross_entropy_loss(1 - np.array(mtest), ppoi_rej.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(18, 4), sharey=False, gridspec_kw={'width_ratios': [3, 1, 2]})\n",
    "\n",
    "idxs = np.arange(len(mtest))\n",
    "idx = idxs[489:510]\n",
    "idx_smc = np.arange(39, 60)\n",
    "nvis = idx.size\n",
    "\n",
    "plt.sca(ax[0])\n",
    "plt.plot(np.array(ppoi_smc)[idx_smc], '-*', label='SMC')\n",
    "plt.plot(np.array(ppoi_rej)[idx], '-x', label='R')\n",
    "plt.plot(np.array(ppoi_hat)[idx], '-o', label='DE')\n",
    "plt.plot(np.array(1 - np.array(mtest))[idx], 'k-', label='true model')\n",
    "\n",
    "plt.ylabel(r'$p(K_{d} | s(x_o))$')\n",
    "plt.xlabel('test set index')\n",
    "plt.xticks(np.arange(0, nvis, 2), np.arange(0, nvis, 2))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.sca(ax[1])\n",
    "# plt.bar([0, 1, 2], [err_rej.mean(), err_smc.mean(), err_de.mean()], color=['C1', 'C2', 'C3'])\n",
    "\n",
    "bp = plt.boxplot([cel_rej, cel_de], notch=True, labels=['R', 'DE'], autorange=True, widths=.7, \n",
    "                 patch_artist=True, medianprops={'color': 'k'});\n",
    "\n",
    "for i, b in enumerate(bp['boxes']): \n",
    "    b.set(facecolor='C{}'.format(i+1))\n",
    "plt.ylabel('mean cross entropy loss')\n",
    "plt.xticks([1, 2], ['R', 'DE'], fontsize=18)\n",
    "\n",
    "plt.sca(ax[2])\n",
    "plt.plot(prior_probs, post_probs_mean_rej, '-oC1', label='R')\n",
    "plt.plot(prior_probs, post_probs_mean, '-oC2', label='DE')\n",
    "plt.plot(prior_probs, prior_probs, label='identity')\n",
    "plt.ylabel(r'mean $p(M_{K_{d}} | s(x_o))$')\n",
    "plt.xlabel(r'prior $p(M_{K_{d}})$')\n",
    "plt.yticks(np.arange(.1, 1., .1), np.arange(.1, 1., .1))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# plt.plot(prior_probs, prior_probs)\n",
    "# plt.plot(np.arange(.1, 1., .2), meanpost_smc, '-o', label='SMC', color='C2')\n",
    "# plt.plot(prior_probs, meanpost_de, '-o', label='DE', color='C3')\n",
    "# plt.ylabel(r'mean $p(M_{Poisson} | s(x_o))$')\n",
    "# plt.xlabel(r'$p(M_{Poisson})$')\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = time_stamp + '_channelexample_priorchecks_errors_ntest{}.png'.format(int(len(mtest)))\n",
    "fig.savefig(os.path.join('../figures', fn), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model parameter posterior \n",
    "\n",
    "Because we do not have the ground truth posteiror we can only check the quantiles and credible intervals of the marginals have a look at the covariances of the joint posterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_post_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xo, sxo, parameter_mdn, GT, labels, sx_train, sx_test, data_norm, prior_norm, params_pred, params_pred_test, predicted_channel_type, loss_trace = p_post_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_test = params_pred_test[:2000, ]\n",
    "sx_test_zt, _ = normalize(sx_test[:2000, ], data_norm)\n",
    "params_test_zt, _ = normalize(params_test, prior_norm)\n",
    "\n",
    "ntest = sx_test_zt.shape[0]\n",
    "ntrain = sx_train.shape[0]\n",
    "n_params = params_pred_test.shape[1]\n",
    "n_components = parameter_mdn.n_components\n",
    "\n",
    "if predicted_channel_type == 'ks': \n",
    "    predicted_channel_type = 'kslow'\n",
    "gt = GT[predicted_channel_type]\n",
    "channel_type = predicted_channel_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantiles, credible intervals for every dimension (5)\n",
    "qis = np.zeros((n_params + 1, ntest))\n",
    "\n",
    "credible_intervals = np.arange(0.05, 1., 0.05)\n",
    "marginal_ci_counts = np.zeros((n_params + 1, ntest, credible_intervals.size))\n",
    "\n",
    "covariances = []\n",
    "\n",
    "ms_hat = []\n",
    "ps_hat = []\n",
    "\n",
    "# for every test sample \n",
    "fails = []\n",
    "\n",
    "with tqdm.tqdm(total=ntest) as pbar: \n",
    "    for ii, (thetao_i, sxo_i) in enumerate(zip(params_test, sx_test_zt)): \n",
    "\n",
    "        theta_zt, _ = normalize(thetao_i, prior_norm)\n",
    "        \n",
    "        # predict the posterior\n",
    "        post_hat_zt = parameter_mdn.predict(sxo_i.reshape(1, -1))\n",
    "        # transform back to original parameter range\n",
    "        post_hat = post_hat_zt.ztrans_inv(prior_norm[0], prior_norm[1])\n",
    "        marginals_hat = post_hat.get_marginals()\n",
    "        \n",
    "        ps_hat.append(post_hat)\n",
    "        ms_hat.append(marginals_hat)\n",
    "       \n",
    "        pbar.update()\n",
    "        # perform check for marginals         \n",
    "        for vi, (mhat, th) in enumerate(zip(marginals_hat, thetao_i)):             \n",
    "            # quantiles \n",
    "            qis[vi, ii] = mhat.get_quantile(th)[0]\n",
    "\n",
    "            # credible intervals\n",
    "            marginal_ci_counts[vi, ii, :] = mhat.get_credible_interval_counts(th, credible_intervals)\n",
    "\n",
    "        # perform checks for joint \n",
    "        vi = n_params\n",
    "\n",
    "        # quantiles \n",
    "        qis[vi, ii] = post_hat_zt.get_quantile(thetao_i.reshape(1, -1))\n",
    "\n",
    "        # covariances\n",
    "#         covariances.append(post_hat.get_covariance_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "mlabels = labels[predicted_channel_type]\n",
    "mlabels[0] = 'M'\n",
    "for mi in range(len(mlabels)):\n",
    "    n, bins = np.histogram(qis[mi, ], bins='auto')\n",
    "    sample_quantiles = np.cumsum(n / np.sum(n))\n",
    "    theo_quantiles = np.linspace(0, 1, len(n))\n",
    "    ax[0].set_title('Q-Q plot')\n",
    "    ax[0].plot(theo_quantiles, sample_quantiles, 'x-', label=mlabels[mi])    \n",
    "    ax[0].legend()\n",
    "    \n",
    "    ax[1].set_title('Credible intervals')\n",
    "    ax[1].plot(credible_intervals, marginal_ci_counts[mi,].mean(axis=0), 'x-', label=mlabels[mi])\n",
    "    ax[1].legend(fontsize=16)\n",
    "    \n",
    "ax[1].grid()\n",
    "ax[0].grid()\n",
    "ax[0].plot(theo_quantiles, theo_quantiles, 'k')\n",
    "ax[1].plot(credible_intervals, credible_intervals, 'k')\n",
    "\n",
    "ax[0].set_ylabel('empirical quantile')\n",
    "ax[0].set_xlabel(r'uniform quantile')\n",
    "ax[1].set_ylabel('relative frequency')\n",
    "ax[1].set_xlabel('credible interval')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = time_stamp + '_channelexample_posteriorchecks_{}_ntrain{}_nc{}.png'.format(channel_type, int(ntrain), n_components)\n",
    "fig.savefig(os.path.join('../figures', fn), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect individual marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = 2\n",
    "prior_lims = prior_lims_kd if predicted_channel_type == 'kd' else prior_lims_ks\n",
    "pp = np.linspace(prior_lims[mi][0], prior_lims[mi][1], 2000)\n",
    "# pp = np.linspace(-2, 2, 2000)\n",
    "\n",
    "for i, m in enumerate(ms_hat): \n",
    "    mhat = m[mi]\n",
    "    q = mhat.get_quantile(params_test[i][mi])[0]\n",
    "    pd = mhat.eval_numpy(pp)\n",
    "    plt.plot(pp, pd, label='q {:.3}'.format(qis[mi, i], q))\n",
    "    plt.axvline(x=params_test[i][mi], color='C{}'.format(i % 9))\n",
    "        \n",
    "    if i == 9: break\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get posterior for gt params \n",
    "# normalize the observed data with training norm \n",
    "sx_obs, data_norm = normalize(sxo.squeeze(), data_norm)\n",
    "# predict MoG parameters given observed data \n",
    "mog_posterior_pytorch = parameter_mdn.predict(sx_obs.reshape(1, -1))\n",
    "# define as delfi distribution\n",
    "mog_posterior_delfi_zt = mog_posterior_pytorch.get_dd_object()\n",
    "# transform back to prior ranges \n",
    "mog_posterior_delfi = mog_posterior_delfi_zt.ztrans_inv(mean=prior_norm[0], std=prior_norm[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_pdf(mog_posterior_delfi, lims=prior_lims, figsize=(18, 10), ticks=True, \n",
    "                   labels_params=labels[predicted_channel_type], gt=gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = time_stamp + '_channelexample_posterior_{}_ntrain{}_nc{}.png'.format(channel_type, int(ntrain), n_components)\n",
    "fig.savefig(os.path.join('../figures', fn), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = mog_posterior_delfi\n",
    "n_params = len(gt)\n",
    "lims = prior_lims\n",
    "cython = True\n",
    "\n",
    "mean, S = posterior.calc_mean_and_cov()\n",
    "# m = posterior.xs[0].m\n",
    "# S = posterior.xs[0].S\n",
    "\n",
    "prot = ['v_act','v_inact','v_deact','v_ap','v_ramp']\n",
    "num_protocols = len(prot)\n",
    "\n",
    "num_samp = 1\n",
    "\n",
    "# sampling at contour of 1 covariance away from mean (if samples from outside the prior box, contour is at prior box)\n",
    "x_samp = np.random.randn(n_params, num_samp)\n",
    "x_samp = np.divide(x_samp, np.linalg.norm(x_samp, axis=0))\n",
    "x_samp = (np.dot(S, x_samp)).T + mean\n",
    "\n",
    "# # sample from posterior\n",
    "# x_samp = posterior.gen(n_samples=num_samp)\n",
    "\n",
    "# correct for samples outside the prior box\n",
    "x_samp = np.maximum(x_samp, lims[:,0])\n",
    "x_samp = np.minimum(x_samp, lims[:,1])\n",
    "\n",
    "params = np.concatenate((np.array([mean]), x_samp))\n",
    "\n",
    "fig = plt.figure(figsize = (20, 8 + num_samp * 4))\n",
    "\n",
    "# set up a simulator \n",
    "m = ChannelSingle(channel_type=channel_type, n_params=n_params, cython=cython)\n",
    "s = ChannelStats(channel_type=predicted_channel_type)\n",
    "\n",
    "for i in range(1+num_samp):\n",
    "    x = m.gen_single(params[i, :])\n",
    "    for p in range(num_protocols):\n",
    "        I = x[prot[p]]['data']\n",
    "        t = x[prot[p]]['time']\n",
    "        num_levels = len(I[:,0])\n",
    "        cm1 = mpl.cm.viridis\n",
    "        col1 = [cm1(1.*k/num_levels) for k in range(num_levels)]\n",
    "        \n",
    "        for j in range(num_levels):\n",
    "            if i==0:\n",
    "                plt.subplot(2+num_samp, num_protocols, p+1)\n",
    "                plt.plot(t, xo[0][0][prot[p]]['data'][j,], color = col1[j], lw=2)\n",
    "                plt.xlabel('time (ms)')\n",
    "                plt.ylabel('norm. current')\n",
    "                plt.title('observation')\n",
    "                \n",
    "                plt.subplot(2+num_samp,num_protocols,num_protocols+p+1)\n",
    "                plt.plot(t, I[j,], color = col1[j], lw=2)\n",
    "                plt.xlabel('time (ms)')\n",
    "                plt.ylabel('norm. current')\n",
    "                plt.title('mode')\n",
    "            else:\n",
    "                plt.subplot(2+num_samp,num_protocols,(i+1)*num_protocols+p+1)\n",
    "                plt.plot(t, I[j,], color = col1[j], lw=2)\n",
    "                plt.xlabel('time (ms)')\n",
    "                plt.ylabel('norm. current')\n",
    "                plt.title('sample '+str(num_samp-i+1))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = time_stamp + '_channelexample_posteriorsamples_{}_ntrain{}_nc{}.png'.format(channel_type, int(ntrain), n_components)\n",
    "fig.savefig(os.path.join('../figures', fn), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save posterior checks results \n",
    "result_dict = dict(qis=qis, qis_hat=qis_hat, dkl_ratios=dkl_ratios,\n",
    "                  marginal_ci_counts=marginal_ci_counts, \n",
    "                  marginal_ci_counts_hat=marginal_ci_counts_hat, \n",
    "                  fails=fails, \n",
    "                  ntest=ntest, \n",
    "                  mus_exact=mus_exact, mus_hat=mus_hat, \n",
    "                  stds_exact=stds_exact, stds_hat=stds_hat, \n",
    "                  credible_intervals=credible_intervals, \n",
    "                  covariances=covariances, \n",
    "                  covariances_hat=covariances_hat, \n",
    "                  params_test=params_test, \n",
    "                  sx_test_zt=sx_test_zt, \n",
    "                  x_test=x_test, \n",
    "                  ps=ps, \n",
    "                  p_hats=ps_hat)\n",
    "\n",
    "fn = time_stamp + 'posterior_checks_results_NB_ntrain{}_ns{}_ntest{}'.format(ntrain, sample_size, ntest) + '.p'\n",
    "with open(os.path.join('../data', fn), 'wb') as outfile: \n",
    "    pickle.dump(result_dict, outfile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mackelab]",
   "language": "python",
   "name": "conda-env-mackelab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
