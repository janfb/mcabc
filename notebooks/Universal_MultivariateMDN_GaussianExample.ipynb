{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from random import shuffle\n",
    "from scipy.stats import beta\n",
    "import scipy.special\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "from utils import *\n",
    "from mdns import Trainer, MultivariateMogMDN, PytorchMultivariateMoG\n",
    "\n",
    "#from sklearn.preprocessing import normalize\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.titlesize'] = 20\n",
    "mpl.rcParams['axes.labelsize'] = 15\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['figure.figsize'] = (15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a MDN for approximating a models with multiple parameters\n",
    "\n",
    "It takes as input the data $x$ **and** the model index $m$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = 2  # 2D problem, better visualization\n",
    "\n",
    "# define a MoG model with n_params + 1 inputs: data dimensions plus model index \n",
    "model = MultivariateMogMDN(ndim_input=n_params + 1, ndim_output=2, n_hidden_units=20, n_components=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "trainer = Trainer(model, optimizer, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data from different models: Gaussian models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use different priors on the mean \n",
    "prior1 = scipy.stats.multivariate_normal(mean=[0.5, 0.5], cov=np.eye(n_params))\n",
    "prior2 = scipy.stats.multivariate_normal(mean=[-0.5, -0.5], cov=np.eye(n_params))\n",
    "\n",
    "# use fixed covariance for both models \n",
    "data_cov = 0.5 * np.eye(n_params)\n",
    "\n",
    "n_samples = 10000\n",
    "sample_size = 1000\n",
    "\n",
    "X1, theta1 = generate_nd_gaussian_dataset(n_samples, sample_size, prior1, data_cov=data_cov)\n",
    "X2, theta2 = generate_nd_gaussian_dataset(n_samples, sample_size, prior2, data_cov=data_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the data into a single data set and add the model index as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack((np.hstack((X1, -1 * np.ones(n_samples).reshape(n_samples, 1))), \n",
    "               np.hstack((X2, np.ones(n_samples).reshape(n_samples, 1)))))\n",
    "X, training_norm = normalize(X)\n",
    "theta = np.vstack((theta1, theta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trace = trainer.train(X, theta, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now approximate the posterior under different models using generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "true_mu = [0, 0]\n",
    "xo = scipy.stats.multivariate_normal.rvs(mean=true_mu, cov=data_cov, size=sample_size).reshape(sample_size, n_params)\n",
    "# generate stats\n",
    "so = np.sum(xo, axis=0).reshape(1, 2)\n",
    "# add model index and normalize\n",
    "so1, norm = normalize(np.hstack((so, np.array([[-1]]))), training_norm)\n",
    "so2, norm = normalize(np.hstack((so, np.array([[1]]))), training_norm)\n",
    "# pytorch \n",
    "so1 = Variable(torch.Tensor(so1.tolist()))\n",
    "so2 = Variable(torch.Tensor(so2.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the posteriors using the predicted parametrization from every model\n",
    "post1 = PytorchMultivariateMoG(*model(so1))\n",
    "post2 = PytorchMultivariateMoG(*model(so2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the true posteriors \n",
    "postana1 = scipy.stats.multivariate_normal(*calculate_multivariate_normal_mu_posterior(xo, data_cov, sample_size, \n",
    "                                           prior1.mean, prior1.cov))\n",
    "postana2 = scipy.stats.multivariate_normal(*calculate_multivariate_normal_mu_posterior(xo, data_cov, sample_size, \n",
    "                                           prior2.mean, prior2.cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a grid of values at which to evaluate the posteriors \n",
    "r = 1.\n",
    "x, y = np.mgrid[-r:r:.01, -r:r:.01]\n",
    "pos = np.dstack((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the posteriors \n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(221)\n",
    "\n",
    "plt.contourf(x, y, post1.eval_numpy(pos))\n",
    "plt.plot(true_mu[0], true_mu[1], 'ro', label='true mean');\n",
    "plt.plot(prior1.mean[0], prior1.mean[1], 'ko', label='prior mean');\n",
    "plt.title('model 1, prior mean {}'.format(prior1.mean));\n",
    "plt.grid()\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.contourf(x, y, post2.eval_numpy(pos))\n",
    "plt.plot(true_mu[0], true_mu[1], 'ro')\n",
    "plt.title('model 2, prior mean {}'.format(prior2.mean));\n",
    "plt.plot(true_mu[0], true_mu[1], 'ro', label='true mean');\n",
    "plt.plot(prior2.mean[0], prior2.mean[1], 'ko', label='prior mean');\n",
    "plt.grid()\n",
    "\n",
    "# plot the true posteriors under each model \n",
    "plt.subplot(222)\n",
    "plt.contourf(x, y, postana1.pdf(pos))\n",
    "plt.title('Analytical posterior model 1')\n",
    "plt.plot(true_mu[0], true_mu[1], 'ro', label='true mean');\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.contourf(x, y, postana2.pdf(pos))\n",
    "plt.title('Analytical posterior model 2')\n",
    "plt.plot(true_mu[0], true_mu[1], 'ro', label='true mean');\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credible Region check \n",
    "Sample a lot of $\\theta$s from the prior, get the data $x$, predict the posterior and get the analytical posterior. Check for many different CR, whether $\\theta# lies in the interval.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample from gaussian prior \n",
    "ntest = 10000\n",
    "thetas = prior1.rvs(ntest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate corresponding data \n",
    "x_test = []\n",
    "for th in thetas: \n",
    "    x_test.append(scipy.stats.multivariate_normal.rvs(mean=th, size=sample_size))\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# calculate summary stats \n",
    "sx_test = np.hstack((np.sum(x_test, axis=1), np.ones((1, ntest)).T))\n",
    "\n",
    "# normalize \n",
    "sx_test_zt, _ = normalize(sx_test, training_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior1.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_credible_regions(theta_o, cdf_fun, credible_regions):\n",
    "    \n",
    "    q = cdf_fun(theta_o)\n",
    "    \n",
    "    if q > 0.5:\n",
    "        # the mass in the CR is 1 - how much mass is above times 2\n",
    "        cr_mass = 1 - 2 * (1 - q)\n",
    "    else:\n",
    "        # or 1 - how much mass is below, times 2\n",
    "        cr_mass = 1 - 2 * q\n",
    "    counts = np.ones_like(credible_regions) * (credible_regions > cr_mass)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each theta, x, sx, predict posterior and get true posterior \n",
    "cr = np.arange(0.05, 1., 0.05)\n",
    "cr_counts = np.zeros((3, cr.size))\n",
    "cr_counts2 = np.zeros_like(cr)\n",
    "for ii, (th, x, sxz) in enumerate(zip(thetas, x_test, sx_test_zt)): \n",
    "    # predict posterior \n",
    "    phat = model.predict(sxz.reshape(1, -1))\n",
    "    [m1, m2] = phat.get_marginals()\n",
    "    cr_counts[0, ] += m1.get_credible_interval_counts(th[0], cr)\n",
    "    cr_counts[1, ] += m2.get_credible_interval_counts(th[1], cr)\n",
    "    cr_counts[2, ] += phat.check_credible_regions(th, cr)\n",
    "    \n",
    "    sigma_0 = prior1.cov \n",
    "    mu_0 = prior1.mean\n",
    "    sigma = np.eye(2)\n",
    "    sigma_N = np.linalg.inv(np.linalg.inv(sigma_0) + sample_size * np.linalg.inv(sigma))\n",
    "    mu_N = sigma_N.dot(sample_size * np.linalg.inv(sigma).dot(x.mean(axis=0)) + np.linalg.inv(sigma_0).dot(mu_0))\n",
    "    post = scipy.stats.multivariate_normal(mean=mu_N, cov=sigma_N)\n",
    "    \n",
    "    cr_counts2 += check_credible_regions(th.reshape(1, -1), post.cdf, cr)\n",
    "cr_probs = cr_counts / ntest\n",
    "cr_probs2 = cr_counts2 / ntest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cr, cr_probs[0, ], '-x', label='mdn posterior, x1 marginal')\n",
    "plt.plot(cr, cr_probs[1, ], '-x', label='mdn posterior, x2 marginal')\n",
    "plt.plot(cr, cr_probs[2, ], '-x', label='mdn posterior, joint')\n",
    "plt.plot(cr, cr_probs2, '-x', label='analytical posterior')\n",
    "plt.plot(cr, cr, '-', lw=3)\n",
    "plt.legend()\n",
    "plt.ylabel(r'P($\\theta$ $\\in$ CR | x)')\n",
    "plt.xlabel('Credible region density')\n",
    "plt.title('Credible region (CR) probabilities for 2D Gaussian fit on the mean');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
