{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from random import shuffle\n",
    "from scipy.stats import gamma, norm\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from model_comparison.utils import *\n",
    "from model_comparison.mdns import *\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Gaussian data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for prior \n",
    "prior_mu = 2. \n",
    "prior_sigma = 4. \n",
    "\n",
    "# set true mean\n",
    "true_mu = 2.\n",
    "\n",
    "N = 1000\n",
    "X_o = np.random.normal(loc=true_mu, size=N)\n",
    "\n",
    "X_var = Variable(torch.Tensor(X_o.astype(float)))\n",
    "\n",
    "plt.hist(X_o, bins=12);\n",
    "plt.xlabel('X');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need to define a generative model to generate samples (theta, x)\n",
    "def generate_dataset(N, m):\n",
    "    # N data sets \n",
    "    # each with m samples \n",
    "    \n",
    "    X = []\n",
    "    thetas = []\n",
    "    \n",
    "    for i in range(N): \n",
    "        # sample from the prior \n",
    "        theta = np.random.normal(prior_mu, prior_sigma)\n",
    "\n",
    "        # generate samples\n",
    "        x = np.random.normal(theta, size=m)\n",
    "        \n",
    "        # as data we append the summary stats\n",
    "        X.append(calculate_stats(x).astype(float)) \n",
    "        thetas.append([theta])\n",
    "    \n",
    "    return np.array(X), np.array(thetas)\n",
    "\n",
    "# calculate summary stats, for poisson this is just x, so for a vector it is sum x\n",
    "def calculate_stats(x): \n",
    "    sx = np.array([np.sum(x).astype(float)])\n",
    "#    sx = x\n",
    "    return sx\n",
    "\n",
    "def batch_generator(dataset, batch_size=5):\n",
    "    shuffle(dataset)\n",
    "    N_full_batches = len(dataset) // batch_size\n",
    "    for i in range(N_full_batches):\n",
    "        idx_from = batch_size * i\n",
    "        idx_to = batch_size * (i + 1)\n",
    "        xs, ys = zip(*[(x, y) for x, y in dataset[idx_from:idx_to]])\n",
    "        yield xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = generate_dataset(10000, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xz, data_norm = normalize(X)\n",
    "yz, prior_norm = normalize(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a network to approximate the posterior with a MoG \n",
    "mdn = UnivariateMogMDN(ndim_input=1, n_components=1)\n",
    "optimizer = torch.optim.Adam(mdn.parameters(), lr=0.01)\n",
    "trainer = Trainer(mdn, optimizer, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = trainer.train(xz, yz.squeeze(), n_epochs=400, n_minibatch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now evaluate the model at the observed data \n",
    "stats_o = calculate_stats(X_o).reshape(1, 1)\n",
    "sxozt, _ = normalize(stats_o, data_norm)\n",
    "thzt, _ = normalize(true_mu, prior_norm)\n",
    "\n",
    "X_var = Variable(torch.Tensor(stats_o))\n",
    "\n",
    "(out_alpha, out_sigma, out_mu) = mdn(X_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thetas = np.linspace(-2, 2, 1000)\n",
    "\n",
    "post = mdn.predict(sxozt)\n",
    "post_vals = post.eval_numpy(thetas)\n",
    "prior = norm.pdf(thetas, loc=prior_mu, scale=prior_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(thetas, post_vals, label='posterior given x_o')\n",
    "plt.plot(thetas, prior, '--', label='prior')\n",
    "plt.axvline(x=thzt, label='true mu', linestyle='--', color='r')\n",
    "plt.xlabel('theta')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Posterior software validation \n",
    "\n",
    "Calculate credible intervals and quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate testing data \n",
    "ntest = 500\n",
    "X, Y = generate_dataset(ntest, N)\n",
    "xz, _ = normalize(X, data_norm)\n",
    "yz, _ = normalize(Y, prior_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run loop over test data: predict posterior, calculate quantiles, check credible intervals\n",
    "qis = np.zeros(ntest)\n",
    "credible_intervals = np.arange(.1, 1., .1)\n",
    "ci_counts = np.zeros((credible_intervals.shape[0], ntest))\n",
    "for ii, (xi, thi) in enumerate(zip(xz, yz)): \n",
    "    # get posterior \n",
    "    post = mdn.predict(xi.reshape(1, -1))\n",
    "    \n",
    "    # get quantile \n",
    "    qis[ii] = post.get_quantile(thi)\n",
    "    \n",
    "    # get ci counts \n",
    "    ci_counts[:, ii] = post.get_credible_interval_counts(thi, credible_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(credible_intervals, ci_counts.mean(axis=1), 'o-')\n",
    "plt.plot(credible_intervals, credible_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(qis, bins='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
