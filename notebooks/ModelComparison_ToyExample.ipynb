{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain model comparison toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import time \n",
    "import tqdm\n",
    "\n",
    "import sys \n",
    "sys.path.append('../../')\n",
    "from model_comparison.utils import *\n",
    "from model_comparison.mdns import *\n",
    "from model_comparison.models import PoissonModel, NegativeBinomialModel\n",
    "\n",
    "from delfi.distribution.mixture import MoG\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Poisson and Negative Binomial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 2\n",
    "rng = np.random.RandomState(seed=seed)\n",
    "time_stamp = time.strftime('%Y%m%d%H%M_')\n",
    "figure_folder = '../figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "sample_size = 10\n",
    "ntrain = 100000\n",
    "ntest = 100\n",
    "\n",
    "k2 = 1.\n",
    "theta2 = 1.0\n",
    "\n",
    "k3 = 2.\n",
    "theta3 = 2. \n",
    "\n",
    "# then the scale of the Gamma prior for the Poisson is given by\n",
    "theta1 = 2.0\n",
    "k1 = (k2 * theta2 * k3 * theta3) / theta1\n",
    "print(k1)\n",
    "\n",
    "\n",
    "model_poisson = PoissonModel(sample_size=sample_size, seed=seed, n_workers=2)\n",
    "model_nb = NegativeBinomialModel(sample_size=sample_size, seed=seed, n_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate parameters from the priors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from Gamma prior for Poisson \n",
    "prior_lam = scipy.stats.gamma(a=k1, scale=theta1)\n",
    "prior_k = scipy.stats.gamma(a=k2, scale=theta2)\n",
    "prior_theta = scipy.stats.gamma(a=k3, scale=theta3)\n",
    "\n",
    "n = ntrain + ntest\n",
    "params_poi = prior_lam.rvs(size=int(n / 2))\n",
    "params_nb = np.vstack((prior_k.rvs(size=int(n / 2)), \n",
    "                       prior_theta.rvs(size=int(n / 2)))).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data from models and calculate summary stats, prepare test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_poi = model_poisson.gen(params_poi)\n",
    "data_nb = model_nb.gen(params_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle and set up model index target vector \n",
    "x_all = np.vstack((data_poi, data_nb))\n",
    "\n",
    "# define model indices\n",
    "m_all = np.hstack((np.zeros(data_poi.shape[0]), np.ones(data_nb.shape[0]))).squeeze().astype(int)\n",
    "\n",
    "# get shuffled indices \n",
    "shuffle_indices = np.arange(n)\n",
    "np.random.shuffle(shuffle_indices)\n",
    "\n",
    "# shuffle the data \n",
    "x_all = x_all[shuffle_indices, ]\n",
    "m_all = m_all[shuffle_indices].tolist()\n",
    "\n",
    "x, xtest = x_all[:ntrain, :], x_all[ntrain:, :]\n",
    "m, mtest = m_all[:ntrain], m_all[ntrain:]\n",
    "\n",
    "# calculate summary stats\n",
    "sx = calculate_stats_toy_examples(x)\n",
    "sx_test = calculate_stats_toy_examples(xtest)\n",
    "# use training norm to normalize test data \n",
    "sx_zt, training_norm = normalize(sx)\n",
    "sx_test_zt, training_norm = normalize(sx_test, training_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the NN and train it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ClassificationMDN(n_input=2, n_hidden_units=10, n_hidden_layers=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "trainer = Trainer(model, optimizer, verbose=True, classification=True)\n",
    "\n",
    "n_epochs = 100 \n",
    "n_minibatch = int(ntrain / 100)\n",
    "\n",
    "# train with training data\n",
    "loss_trace = trainer.train(sx_zt, m, n_epochs=n_epochs, n_minibatch=n_minibatch)\n",
    "plt.plot(loss_trace)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppoi_exact = []\n",
    "with tqdm.tqdm(total=len(mtest), desc='Calculate evidences for test samples', ncols=110) as pbar: \n",
    "    for xi in xtest: \n",
    "        nb_logevi = calculate_nb_evidence(xi, k2, theta2, k3, theta3, log=True)\n",
    "        poi_logevi = poisson_evidence(xi, k=k1, theta=theta1, log=True)\n",
    "        ppoi_exact.append(calculate_pprob_from_evidences(np.exp(poi_logevi), np.exp(nb_logevi)))\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ms, vs = np.meshgrid(np.linspace(0, 300, 100), np.linspace(0, 400, 100))\n",
    "# stack values to evaluate as vector in the model \n",
    "sx_vis = np.vstack((ms.flatten(), vs.flatten())).T\n",
    "# normalize \n",
    "sx_vis, training_norm = normalize(sx_vis, training_norm)\n",
    "\n",
    "\n",
    "# predict probs \n",
    "ppoi_vec = model.predict(sx_vis)\n",
    "# take poisson posterior prob and reshape to grid dimensions\n",
    "ppoi_vismat = ppoi_vec[:, 0].reshape(ms.shape[0], vs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "cnorm = mpl.colors.Normalize(vmin=ppoi_vismat.min(), vmax=ppoi_vismat.max())\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "plt.scatter(x=sx_test[:, 0], y=sx_test[:, 1], c=np.array(ppoi_exact), cmap=cmap, \n",
    "            norm=cnorm, edgecolors='r', linewidths=0.3)\n",
    "plt.imshow(ppoi_vismat, origin='lower', aspect='auto', \n",
    "           norm=cnorm, cmap=cmap, extent=[ms.min(), ms.max(), vs.min(), vs.max()])\n",
    "\n",
    "plt.xlabel('Sample mean')\n",
    "plt.ylabel('Sample variance')\n",
    "plt.colorbar(label='P(Poisson | x)', pad=0.01)\n",
    "plt.legend(['Exact posterior probabilities'])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe Poisson data and predict underlying model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a single sample of Poisson data, with lambda at the mean of the model prior \n",
    "true_lambda = rng.gamma(shape=k1, scale=theta1)\n",
    "x_obs = rng.poisson(lam=true_lambda, size=sample_size)\n",
    "# calculate stats \n",
    "sx_obs = calculate_stats_toy_examples(x_obs)\n",
    "# normalize using training data normalization \n",
    "sx_obs_zt, training_norm = normalize(sx_obs, training_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict \n",
    "p_vec = model.predict(sx_obs_zt).squeeze()\n",
    "# calculate exact evidence \n",
    "nb_evidence = calculate_nb_evidence(x_obs, k2, theta2, k3, theta3, log=True)\n",
    "poi_evidence = poisson_evidence(x_obs, k=k1, theta=theta1, log=True)\n",
    "ppoi_ana = calculate_pprob_from_evidences(np.exp(poi_evidence), np.exp(nb_evidence))\n",
    "\n",
    "print(r'predicted P(poisson | data) = {:.2f}'.format(p_vec[0]))\n",
    "print(r'exact P(poisson | data) = {:.2f}'.format(ppoi_ana))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_modelpost = dict(seed=seed, trainer=trainer, model_models=model,\n",
    "                       x=x, m=m, xtest=xtest, mtest=mtest, \n",
    "                       sx=sx, sx_test=sx_test, \n",
    "                       training_norm=training_norm, param_poi=params_poi, params_nb=params_nb, \n",
    "                       theta1=theta1, theta2=theta2, theta3=theta3, \n",
    "                       k1=k1, k2=k2, k3=k3, \n",
    "                       sample_size=sample_size, n_samples=ntrain, \n",
    "                       ppoi_exact=ppoi_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given the predicted underlying model we can learn the posterior of its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a network to approximate the posterior with a MoG \n",
    "model_params_mdn = UnivariateMogMDN(ndim_input=2, n_hidden=10, n_components=2)\n",
    "optimizer = torch.optim.Adam(model_params_mdn.parameters(), lr=0.01)\n",
    "trainer = Trainer(model_params_mdn, optimizer, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate stats for poisson model \n",
    "sx_poi = calculate_stats_toy_examples(data_poi)\n",
    "\n",
    "# normalize data \n",
    "sx_poi_zt, data_norm = normalize(sx_poi)\n",
    "\n",
    "# normalize prior params \n",
    "params_poi_zt, prior_norm = normalize(params_poi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 100/100 [00:23<00:00,  4.36it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_trace = trainer.train(sx_poi_zt, params_poi_zt, n_epochs=100, n_minibatch=int(n / 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0e3667b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_thetas = 1000\n",
    "thetas_poisson = np.linspace(0, 20, n_thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sx_obs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c1215deeb392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# normalize the observed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msx_obs_zt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sx_obs' is not defined"
     ]
    }
   ],
   "source": [
    "# normalize the observed data \n",
    "sx_obs_zt, data_norm = normalize(sx_obs, data_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get delfi MoG for plotting and inverse z transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a single sample of Poisson data, with lambda at the mean of the model prior \n",
    "true_lambda = rng.gamma(shape=k1, scale=theta1)\n",
    "x_obs = rng.poisson(lam=true_lambda, size=sample_size)\n",
    "# calculate stats \n",
    "sx_obs = calculate_stats_toy_examples(x_obs)\n",
    "# normalize using training data normalization \n",
    "sx_obs_zt, _ = normalize(sx_obs, data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(out_mu, out_sigma, out_alpha) = model_params_mdn(Variable(torch.Tensor(sx_obs_zt)))\n",
    "\n",
    "# convert to dd format \n",
    "a = out_alpha.data.numpy().squeeze().tolist()\n",
    "ms = [[m] for m in out_mu.data.numpy().squeeze().tolist()]\n",
    "Ss = [[[s**2]] for s in out_sigma.data.numpy().squeeze().tolist()]\n",
    "\n",
    "# set up dd MoG object \n",
    "mog_posterior_delfi_zt = MoG(a=a, ms=ms, Ss=Ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform back to prior ranges \n",
    "mog_posterior_delfi = mog_posterior_delfi_zt.ztrans_inv(mean=prior_norm[0], std=prior_norm[1])\n",
    "posterior_pdvalues = mog_posterior_delfi.eval(x=thetas_poisson.reshape(1000, -1), log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get true posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get analytical gamma posterior \n",
    "k_post = k1 + np.sum(x_obs)\n",
    "\n",
    "# use the posterior given the summary stats, not the data vector \n",
    "scale_post = 1. / (sample_size + theta1**-1)\n",
    "\n",
    "# somehow we have to scale with N again, why? because the scale is changed due to s(x) by 1/N  \n",
    "true_post_poisson = gamma.pdf(x=thetas_poisson, a=k_post, scale=scale_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(r'Gamma posterior fit for Poisson $\\lambda$')\n",
    "# plt.plot(thetas_poisson, gamma_prior.pdf(thetas_poisson), label='prior')\n",
    "plt.plot(thetas_poisson, true_post_poisson, label='analytical posterior')\n",
    "plt.plot(thetas_poisson, posterior_pdvalues, label='predicted posterior')\n",
    "plt.axvline(x=k1 * theta1, color=\"C2\", label='true lambda')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$\\lambda$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate test data \n",
    "ntest = 1000\n",
    "params_test = prior_lam.rvs(size=ntest)\n",
    "params_test_zt, _ = normalize(params_test, prior_norm)\n",
    "\n",
    "x_test = model_poisson.gen(params_test)\n",
    "sx_test = calculate_stats_toy_examples(x_test)\n",
    "sx_test_zt, _ = normalize(sx_test, data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# qis = np.zeros(ntest)\n",
    "nbreak = ntest\n",
    "qis = np.zeros(nbreak)\n",
    "# for every test sample \n",
    "for ii, (thetao_i, sxo_i) in enumerate(zip(params_test_zt, sx_test_zt)): \n",
    "    \n",
    "    # predict the posterior\n",
    "    posterior = model_params_mdn.predict(sxo_i.reshape(1, -1))\n",
    "    \n",
    "    # get quantile of theta_o\n",
    "    qis[ii] = posterior.get_quantile(thetao_i)\n",
    "    if ii==nbreak-1: \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of uniformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.kstest(qis, cdf='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n, bins, patch = plt.hist(qis, bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## We can also observe NB data, predict idx and learn the posterior\n",
    "The NB posterior is 2D, one dimension for $k$ and once for $\\theta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a network to approximate the posterior with a MoG \n",
    "model_params_mdn = MultivariateMogMDN(ndim_input=2, ndim_output=2, n_hidden_units=10, \n",
    "                                      n_hidden_layers=2, n_components=2)\n",
    "optimizer = torch.optim.Adam(model_params_mdn.parameters(), lr=0.01)\n",
    "trainer = Trainer(model_params_mdn, optimizer, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate stats for poisson model \n",
    "sx_nb = calculate_stats_toy_examples(data_nb)\n",
    "\n",
    "# normalize data \n",
    "sx_nb_zt, data_norm = normalize(sx_nb)\n",
    "\n",
    "# normalize prior params \n",
    "params_nb_zt, prior_norm = normalize(params_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_trace = trainer.train(sx_nb_zt, params_nb_zt, n_epochs=200, n_minibatch=int(sx_nb.shape[0] / 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "plt.plot(loss_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe NB data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thetao = [[prior_k.rvs(), prior_theta.rvs()]]\n",
    "xo = model_nb.gen(thetao)\n",
    "sxo = calculate_stats_toy_examples(xo)\n",
    "sxo_zt, _ = normalize(sxo, data_norm)\n",
    "thetao_zt, _ = normalize(thetao, prior_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict posterior and transform to absolut range\n",
    "phat = model_params_mdn.predict(sxo_zt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(phat.mean, thetao_zt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a way to compare to the exact posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile check \n",
    "\n",
    "ToDo: \n",
    "    - multivariate quantile check DONE \n",
    "    - derive exact posterior \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate test data \n",
    "ntest = 1000\n",
    "params_test = np.vstack((prior_k.rvs(ntest), prior_theta.rvs(ntest))).T\n",
    "params_test_zt, _ = normalize(params_test, prior_norm)\n",
    "\n",
    "x_test = model_nb.gen(params_test)\n",
    "sx_test = calculate_stats_toy_examples(x_test)\n",
    "sx_test_zt, _ = normalize(sx_test, data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qis = np.zeros(ntest)\n",
    "# for every test sample \n",
    "for ii, (thetao_i, sxo_i) in enumerate(zip(params_test_zt, sx_test_zt)): \n",
    "    \n",
    "    # predict the posterior\n",
    "    posterior = model_params_mdn.predict(sxo_i.reshape(1, -1))\n",
    "    \n",
    "    # get quantile of theta_o\n",
    "    qis[ii] = posterior.get_quantile(thetao_i.reshape(1, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(qis, bins='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "either the fit is very bad or the quantile calculation is wrong. double check by deriving the exact posterior and compute it numerically. then one can see the goodness of the fit in terms of dkl, means and std. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
