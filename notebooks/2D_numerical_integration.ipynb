{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to perform numerical integration in 2D + demo with Poisson and NB evidence\n",
    "\n",
    "There are routines in scipy for 1D numerical intragtion, e.g., quad or trapz. While quad gets the actual function to integrated and just the interval for the integration and then performs the sampling and stuff itself, trapz only requires an array of precomputed function values on the domain in question and a stepsize or sampling points correspinding to the precomputed function values. It then uses the trapezoid method to calculate the integral. \n",
    "\n",
    "Now, for 2D there is a dblquad method that does just the same in higher dimensions. However, it gives negative values, probably due to rounding errors or so. So I might want to precalculate the function values and use something like trapz in 2D. However, this does not exist in numpy or scipy it seems. \n",
    "\n",
    "So let us check whether we can just use the 1D trapz method on every axis instead. Let us take a known 2D integral and check the different methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy.integrate\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt \n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from utils import poisson_evidence, poisson_sum_evidence, nbinom_evidence, nbinom_sum_evidence\n",
    "%matplotlib inline \n",
    "\n",
    "from scipy.special import gammaln, gamma, betaln, beta\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.titlesize'] = 20\n",
    "mpl.rcParams['axes.labelsize'] = 15\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "mpl.rcParams['figure.figsize'] = (15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the function \n",
    "fun = lambda x, y: x**2 + y**2\n",
    "\n",
    "# define the domain \n",
    "x1 = -1 \n",
    "x2 = 1 \n",
    "y1 = -1 \n",
    "y2 = 1\n",
    "\n",
    "# set the result \n",
    "result = 8 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct grid of values for trapz \n",
    "x, y = np.meshgrid(np.linspace(-1, 1, 1000), np.linspace(-1, 1, 1000))\n",
    "fun_mat = fun(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use quad \n",
    "rquad = scipy.integrate.dblquad(fun, -1, 1, lambda x: -1, lambda x: 1)\n",
    "\n",
    "# use doubple trapz\n",
    "rtrapz = np.trapz(np.trapz(fun_mat, np.linspace(-1, 1, 1000), axis=0), np.linspace(-1, 1, 1000), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrapz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rquad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "trapz is a bit less accurate, but it seems possible to just apply it along each axis of the precomputed matrix of function values. \n",
    "\n",
    "## Follow up: test the integration for complicated evidence integrals \n",
    "\n",
    "### First for Poisson evidence with ground truth\n",
    "\n",
    "There are different ways for computing the Poisson evidence. One can just see a sample as a vector of i.i.d. single samples. Or one can see it in terms of the sufficient statistics, which is just the sum over the sample. The sum of i.i.d. Poisson samples is again Poissonian with a different rate. The corresponding derivations for the likelihood, prior and marginal likelihood differ by a multiplicative factor. I dont know which is the correct way to do it here, so I just try out both. I call the functions that take the point of view of the sufficient statistics **poisson_sum_evidence** and **poisson_sum_integrant**. \n",
    "\n",
    "The evidence function give the closed form solutions. The integrant function give the functions under the integral. We test the integration method by comparing the results. \n",
    "\n",
    "The different POV give different results unless corrected with multiplicative factor I derived. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poisson_integrant(lam, x, k, theta, log=True): \n",
    "    sx = np.sum(x)   \n",
    "    N = x.size\n",
    "    prior = scipy.stats.gamma(a=k, scale=theta)\n",
    "    # the prod of faculties \n",
    "    denominator = np.sum(gammaln(x + 1))\n",
    "    \n",
    "    # lam ** (sx) * np.exp(-N * lam) * prior.pdf(lam) / denominator\n",
    "    log_integrant = sx * np.log(lam) - N * lam + np.log(prior.pdf(lam)) - denominator\n",
    "    \n",
    "    return np.exp(log_integrant)\n",
    "\n",
    "def poisson_sum_integrant(eta, x, k, theta): \n",
    "    sx = np.sum(x)   \n",
    "    N = x.size\n",
    "    prior = scipy.stats.gamma(a=k, scale=N * theta)\n",
    "    # the prod of faculties \n",
    "    denominator = gammaln(sx + 1)\n",
    "    log_integrant = sx * np.log(eta) - eta + np.log(prior.pdf(eta)) - denominator\n",
    "    \n",
    "    return np.exp(log_integrant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Poisson data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the prior \n",
    "k1 = 5. \n",
    "theta1 = 2. \n",
    "prior = scipy.stats.gamma(a=k1, scale=theta1)\n",
    "\n",
    "# sample data \n",
    "sample_size = 100\n",
    "x = scipy.stats.poisson.rvs(mu=prior.rvs(), size=sample_size)\n",
    "sx = np.sum(x)\n",
    "N = x.size\n",
    "# calculate the scaling between the different POVs\n",
    "i = sx * np.log(N) + np.sum(gammaln(x + 1)) - gammaln(sx + 1)\n",
    "i = np.exp(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ground truths\n",
    "result1 = poisson_sum_evidence(x, k1, theta1, log=False)\n",
    "result2 = poisson_evidence(x, k1, theta1)\n",
    "print('sx based: {} \\n x based: {}'.format(result1, result2))\n",
    "print('corrected: {}'.format(i * result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the integration, again for both POV separately\n",
    "lambs = np.linspace(1e-8, 100, 1000)\n",
    "values = np.array([poisson_integrant(lam, x, k1, theta1) for lam in lambs])\n",
    "values2 = np.array([poisson_sum_integrant(N * lam, x, k1, theta1) for lam in lambs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('traps x based, corrected: ', i * np.trapz(values, lambs))\n",
    "print('traps sx based: ', np.trapz(values2, N * lambs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('scipy x based: ', scipy.integrate.quad(poisson_integrant, 1e-8, 20, args=(x, k1, theta1))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now test with NegBin evidence integral\n",
    "\n",
    "There are different ways for formulating the evidence, e.g., for formulating the prefactor containing the binomial coef. I matched them to give the same result for the data POV. This points in the direction that this is the correct way. I also found a PhD thesis using that formulatin here: \n",
    "https://www.casact.org/pubs/forum/99wforum/wf99377.pdf\n",
    "\n",
    "So, I should take this one for now. The sufficient stats POV has the additional problem that the integration and the closed form dont give the same result. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first define the integrant functions in different POVs     \n",
    "def nb_sum_integrant(p, r, x, a, b): \n",
    "    \n",
    "    N = x.size\n",
    "    sx = np.sum(x)\n",
    "    bc = scipy.special.binom(sx + N * r - 1, sx)\n",
    "    \n",
    "    log_integrant = np.log(bc) + (b + N * r - 1) * np.log(1 - p) + (a + sx - 1) * np.log(p) - betaln(a, b)\n",
    "    \n",
    "    return np.exp(log_integrant)\n",
    "    \n",
    "def nb_evidence(r, x, a, b, log=True): \n",
    "    N = x.size\n",
    "    sx = np.sum(x) \n",
    "    bc = scipy.special.binom(x + r - 1, x)\n",
    "    \n",
    "    log_evidence = np.sum(np.log(bc)) + betaln(a + sx, b + N * r) - betaln(a, b)\n",
    "    \n",
    "    return log_evidence if log else np.exp(log_evidence)\n",
    "    \n",
    "def nb_integrant(p, r, x, a, b): \n",
    "    \n",
    "    N = x.size\n",
    "    sx = np.sum(x)\n",
    "    bc = scipy.special.binom(x + r - 1, x)\n",
    "    \n",
    "    fac = np.prod(bc) / beta(a, b)\n",
    "    \n",
    "    integrant = p**(a + sx - 1) * (1 - p)**(b + N*r - 1)\n",
    "    \n",
    "    return fac * integrant\n",
    "\n",
    "\n",
    "def nb_integrant2(p, x, r, a, b): \n",
    "    N = x.size\n",
    "    sx = np.sum(x)\n",
    "    \n",
    "    fac = np.sum(gammaln(x + r) - (gammaln(x + 1) + gammaln(r))) - betaln(a, b)\n",
    "    integrant = np.log(p) * (a + sx - 1) + np.log(1 - p)*(b + N*r - 1)\n",
    "    \n",
    "    return np.exp(integrant + fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data \n",
    "r = 4\n",
    "a = b = 2\n",
    "prior = scipy.stats.beta(a=a, b=b)\n",
    "\n",
    "sample_size = 100\n",
    "x = scipy.stats.nbinom.rvs(n=r, p=prior.rvs(), size=sample_size)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the integral values on a 1D grid \n",
    "ps = np.linspace(1e-7, .9999, 1000)\n",
    "values1 = np.array([nb_sum_integrant(p, r, x, a, b) for p in ps])\n",
    "values2 = np.array([nb_integrant(p, r, x, a, b) for p in ps])\n",
    "values3 = np.array([nb_integrant2(p, x, r, a, b) for p in ps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ground truth: \n",
    "print('ana sx based: ', nbinom_sum_evidence(x, r, a, b, log=False))\n",
    "print('ana x based: ', nb_evidence(r, x, a, b, log=False))\n",
    "print('ana x new: ', nbinom_evidence(x, r, a, b, log=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = x.size\n",
    "sx = np.sum(x)\n",
    "\n",
    "print('traps sx based: ', np.trapz(values1, ps))\n",
    "print('traps x based: ', np.trapz(values2, ps))\n",
    "print('traps x new: ', np.trapz(values3, ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mackelab]",
   "language": "python",
   "name": "conda-env-mackelab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
