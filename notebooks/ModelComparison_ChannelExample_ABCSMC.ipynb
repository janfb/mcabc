{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pickle\n",
    "import sys \n",
    "import tempfile\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "from lfimodels.channelomics.ChannelSingle import ChannelSingle\n",
    "from lfimodels.channelomics.ChannelStats import ChannelStats\n",
    "\n",
    "from pyabc import (ABCSMC, RV,\n",
    "                   PercentileDistanceFunction, DistanceFunction, sampler)\n",
    "from pyabc import Distribution as abcDis\n",
    "\n",
    "sys.path.append('../../')\n",
    "from model_comparison.utils import *\n",
    "from model_comparison.mdns import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the channel model generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT = {'kd': np.array([[4, -63, 0.032, 15, 5, 0.5, 10, 40]]),\n",
    "      'kslow': np.array([[1, 35, 10, 3.3, 20]])}\n",
    "\n",
    "LP = {'kd': ['power',r'$V_T$',r'$R_{\\alpha}$',r'$th_{\\alpha}$', r'$q_{\\alpha}$', r'$R_{\\beta}$', r'$th_{\\beta}$',\n",
    "             r'$q_{\\beta}$'],\n",
    "      'kslow': ['power', r'$V_T$', r'$q_p$', r'$R_{\\tau}$', r'$q_{\\tau}$']}\n",
    "\n",
    "E_channel = {'kd': -90.0, 'kslow': -90.0}\n",
    "fact_inward = {'kd': 1, 'kslow': 1}\n",
    "\n",
    "prior_lims_kd = np.sort(np.concatenate((0.3 * GT['kd'].reshape(-1, 1), 1.3 * GT['kd'].reshape(-1, 1)), axis=1))\n",
    "prior_lims_ks = np.sort(np.concatenate((0.3 * GT['kslow'].reshape(-1, 1), 1.3 * GT['kslow'].reshape(-1, 1)), axis=1))\n",
    "\n",
    "cython = True\n",
    "seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_obs = ChannelSingle(channel_type='kd', n_params=8, cython=cython)\n",
    "s = ChannelStats(channel_type='kd')\n",
    "\n",
    "xo = m_obs.gen(GT['kd'].reshape(1,-1))\n",
    "sxo = s.calc(xo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkd = ChannelSingle(channel_type='kd', n_params=8, cython=cython, seed=seed)\n",
    "skd = ChannelStats(channel_type='kd', seed=seed)\n",
    "\n",
    "mks = ChannelSingle(channel_type='kslow', n_params=5, cython=cython, seed=seed)\n",
    "sks = ChannelStats(channel_type='kslow', seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define PyABC SMC models and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models oin pyabc style \n",
    "def model_1(parameters):\n",
    "    params = np.array([parameters.p1, parameters.p2, parameters.p3, parameters.p4, \n",
    "                       parameters.p5, parameters.p6, parameters.p7, parameters.p8])\n",
    "    x = mkd.gen(params.reshape(1, -1))\n",
    "    sx = skd.calc(x[0])\n",
    "    return {'y': sx}\n",
    "\n",
    "def model_2(parameters):\n",
    "    params = np.array([parameters.p1, parameters.p2, parameters.p3, parameters.p4, parameters.p5])\n",
    "    x = mks.gen(params.reshape(1, -1))\n",
    "    sx = sks.calc(x[0])\n",
    "    return {'y': sx}\n",
    "\n",
    "# priors\n",
    "prior_dict_kd = dict()\n",
    "for i in range(8): \n",
    "    prior_dict_kd['p{}'.format(i + 1)] = dict(type='uniform', \n",
    "                                              kwargs=dict(loc=prior_lims_kd[i, 0], \n",
    "                                                         scale=prior_lims_kd[i, 1] - prior_lims_kd[i, 0]))\n",
    "    \n",
    "prior1 = abcDis.from_dictionary_of_dictionaries(prior_dict_kd)\n",
    "\n",
    "prior_dict_ks = dict()\n",
    "for i in range(5): \n",
    "    prior_dict_ks['p{}'.format(i + 1)] = dict(type='uniform', \n",
    "                                              kwargs=dict(loc=prior_lims_ks[i, 0], \n",
    "                                                          scale=prior_lims_ks[i, 1] - prior_lims_ks[i, 0]))\n",
    "\n",
    "prior2 = abcDis.from_dictionary_of_dictionaries(prior_dict_ks)\n",
    "\n",
    "models = [model_1, model_2]\n",
    "parameter_priors = [prior1, prior2]\n",
    "\n",
    "class MyDist(DistanceFunction): \n",
    "    \n",
    "    def __call__(self, x, y): \n",
    "        return np.power(x['y'] - y['y'], 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple rejection sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'training_data_kd_ks_N100seed1.p'\n",
    "with open(os.path.join('../data', fn), 'rb') as f: \n",
    "    dtest = pickle.load(f)\n",
    "dtest.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx_test_ks = dtest['sx_ks']\n",
    "sx_test_kd = dtest['sx_kd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load learned posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'learned_posteriors_pospischil_ntrain192962.p'\n",
    "with open(os.path.join('../data', fn), 'rb') as f: \n",
    "    dpost = pickle.load(f)['model_idx_posterior']\n",
    "dpost.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upto = 1\n",
    "test_set = np.vstack((sx_test_kd[:upto, ], sx_test_ks[:upto, ]))\n",
    "mtest = np.hstack((np.zeros(upto), np.ones(upto))).astype(int).tolist()\n",
    "ntest = test_set.shape[0]\n",
    "phat_smc = np.zeros((ntest, 2))\n",
    "phat_mdn = np.zeros((ntest, 2))\n",
    "\n",
    "# get mdn \n",
    "model_mdn = dpost['model_idx_mdn']\n",
    "data_norm = dpost['data_norm']\n",
    "\n",
    "n_rounds = 3\n",
    "n_simulations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in tqdm.tqdm(range(ntest)): \n",
    "    sxo = test_set[ii, ]\n",
    "    \n",
    "    # predict with mdn \n",
    "    sxo_zt, _ = normalize(sxo, data_norm)\n",
    "    phat_mdn[ii, ] = model_mdn.predict(sxo_zt.reshape(1, -1))\n",
    "    \n",
    "    # We plug all the ABC options together\n",
    "    abc = ABCSMC(\n",
    "        models, parameter_priors, MyDist())\n",
    "\n",
    "    # and we define where to store the results\n",
    "    db_path = (\"sqlite:///\" +\n",
    "               os.path.join(tempfile.gettempdir(), \"test.db\"))\n",
    "    abc_id = abc.new(db_path, {\"y\": sxo})\n",
    "\n",
    "    history = abc.run(minimum_epsilon=1e-7, max_nr_populations=n_rounds)\n",
    "    model_probabilities = history.get_model_probabilities()\n",
    "    print(model_probabilities)\n",
    "    print(history.total_nr_simulations)\n",
    "    \n",
    "    phat_smc[ii, 0] = model_probabilities[0][model_probabilities.shape[0] - 1]\n",
    "    phat_smc[ii, 1] = 1 - phat_smc[ii, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(mtest=mtest, sx_test=test_set, ppoi_hat=phat_mdn[:, 0], ppoi_smc=phat_smc[:, 0], data_norm=data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = time.strftime('%Y%m%d%H%M_')\n",
    "\n",
    "fn = time_stamp + '_modelposterior_comparison_channels_ntest{}.p'.format(ntest)\n",
    "with open(os.path.join('../data', fn), 'wb') as outfile: \n",
    "    pickle.dump(d, outfile, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
