{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from delfi.generator import Default\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "from lfimodels.channelomics.ChannelSingle import ChannelSingle\n",
    "from lfimodels.channelomics.ChannelSuper import ChannelSuper\n",
    "from lfimodels.channelomics.ChannelStats import ChannelStats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys \n",
    "sys.path.append('../../')\n",
    "from model_comparison.utils import *\n",
    "from model_comparison.mdns import ClassificationSingleLayerMDN, Trainer, MultivariateMogMDN, PytorchMultivariateMoG\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set groung truth\n",
    "GT = {'k': np.array([9, 25, 0.02, 0.002]),\n",
    "      'na': np.array([-35, 9, 0.182, 0.124, -50, -75, 5, -65, 6.2, 0.0091, 0.024])}\n",
    "\n",
    "LP = {'k': ['qa','tha','Ra','Rb'],\n",
    "      'na': ['tha','qa','Ra','Rb','thi1','thi2','qi','thinf','qinf','Rg','Rd']}\n",
    "\n",
    "E_channel = {'k': -86.7, 'na': 50}\n",
    "fact_inward = {'k': 1, 'na': -1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set \"k\" as underlying ground truth model, generate observed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_type = 'k'\n",
    "gt = GT[channel_type]\n",
    "cython = True\n",
    "third_exp_model = True\n",
    "\n",
    "n_params = len(gt)\n",
    "labels_params = LP[channel_type]\n",
    "prior_lims = np.sort(np.concatenate((0.5 * gt.reshape(-1,1), 1.5 * gt.reshape(-1,1)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ChannelSuper(channel_type=channel_type, third_exp_model=third_exp_model, cython=cython)\n",
    "p = dd.Uniform(lower=prior_lims[:,0], upper=prior_lims[:,1])\n",
    "s = ChannelStats(channel_type=channel_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate observed data\n",
    "n_params_obs = len(gt)\n",
    "m_obs = ChannelSingle(channel_type=channel_type, n_params=n_params_obs, cython=cython)\n",
    "xo = m_obs.gen(gt.reshape(1,-1))\n",
    "xo_stats = s.calc(xo[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'training_data_k_na_N10000seed1.p'\n",
    "folder = '../data/'\n",
    "fullpath = os.path.join(folder, filename)\n",
    "\n",
    "with open(fullpath, 'rb') as f: \n",
    "    result_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_k, sx_k, gt_k, prior_lims_k, params_na, sx_na, gt_na, prior_lims_na, seed, n_samples, cython = result_dict.values()\n",
    "\n",
    "ntrain, n_stats = sx_k.shape\n",
    "\n",
    "# shuffle and set up model index target vector \n",
    "sx = np.vstack((sx_k, sx_na))\n",
    "\n",
    "# define model indices\n",
    "m = np.hstack((np.zeros(ntrain), np.ones(ntrain))).squeeze().astype(int)\n",
    "\n",
    "# shuffle data\n",
    "shuffle_indices = np.arange(ntrain)\n",
    "np.random.shuffle(shuffle_indices)\n",
    "sx = sx[shuffle_indices,]\n",
    "m = m[shuffle_indices].tolist()\n",
    "\n",
    "# normalize\n",
    "sx, training_norm = normalize(sx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Set up the NN and train it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_models = ClassificationSingleLayerMDN(ndim_input=n_stats, n_hidden=10)\n",
    "optimizer = torch.optim.Adam(model_models.parameters(), lr=0.01)\n",
    "trainer = Trainer(model_models, optimizer, verbose=True, classification=True)\n",
    "\n",
    "n_epochs = 100 \n",
    "n_minibatch = int(ntrain / 100)\n",
    "\n",
    "# train with training data\n",
    "loss_trace = trainer.train(sx, m, n_epochs=n_epochs, n_minibatch=n_minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(loss_trace[:100])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict underlying model given observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict \n",
    "# normalize using training data normalization \n",
    "sx_obs, training_norm = normalize(xo_stats.squeeze(), training_norm)\n",
    "\n",
    "softmax = nn.Softmax(dim=0)\n",
    "out_act = model_models(Variable(torch.Tensor(sx_obs)))\n",
    "p_vec = softmax(out_act).data.numpy()\n",
    "print('P(K | sx) = {:.2f}'.format(p_vec[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given the predicted underlying model we can learn the posterior of its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a network to approximate the posterior with a MoG \n",
    "model_params = MultivariateMogMDN(ndim_input=n_stats, ndim_output=params_k.shape[1], n_hidden=10, n_components=3)\n",
    "optimizer = torch.optim.Adam(model_params.parameters(), lr=0.01)\n",
    "trainer = Trainer(model_params, optimizer, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx_k_normed, training_norm = normalize(sx_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trace = trainer.train(sx_k_normed, params_k, n_epochs=100, n_minibatch=int(ntrain / 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(loss_trace[:100])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx_obs, training_norm = normalize(xo_stats.squeeze(), training_norm)\n",
    "sx_obs_pt = Variable(torch.Tensor(sx_obs.reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post1 = PytorchMultivariateMoG(*model_params(sx_obs_pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = post1.alphas.data.numpy()\n",
    "mus = post1.mus[0, :, np.argmax(alphas)].data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post1.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([t for t in gt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([t for t in mus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
