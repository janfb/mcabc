{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os \n",
    "import pickle\n",
    "import sys \n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "sys.path.append('../../')\n",
    "from model_comparison.utils import *\n",
    "from model_comparison.mdns import *\n",
    "from model_comparison.models import PoissonModel, NegativeBinomialModel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl_params = {'legend.fontsize': 14,\n",
    "              'legend.frameon': False,\n",
    "                      'axes.titlesize': 20,\n",
    "                      'axes.labelsize': 17,\n",
    "                      'xtick.labelsize': 12,\n",
    "                      'ytick.labelsize': 12,\n",
    "             'figure.figsize' : (18, 5)}\n",
    "\n",
    "mpl.rcParams.update(mpl_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained NB posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = '../data/'\n",
    "fn = 'learned_posterior_nbmodel_ntrain100000.p'\n",
    "time_stamp = time.strftime('%Y%m%d%H%M_')\n",
    "\n",
    "with open(os.path.join(folder, fn), 'rb') as f: \n",
    "    d = pickle.load(f)\n",
    "    \n",
    "# set the seed for generating new test data \n",
    "seed = 3\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# priors \n",
    "prior_k = d['prior_k']\n",
    "prior_theta = d['prior_theta']\n",
    "sample_size = d['sample_size']\n",
    "ntrain = d['ntrain']\n",
    "param_norm = d['param_norm']\n",
    "data_norm = d['data_norm']\n",
    "\n",
    "model_nb = d['model']\n",
    "model_params_mdn = d['mdn']\n",
    "loss_trace = d['trainer'].loss_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "plt.plot(loss_trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample new test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntest = 100\n",
    "params_test = np.vstack((prior_k.rvs(size=ntest), prior_theta.rvs(size=ntest))).T\n",
    "x_test = model_nb.gen(params_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sx_test = calculate_stats_toy_examples(x_test)\n",
    "sx_test_zt, _ = normalize(sx_test, data_norm)\n",
    "params_test_zt, _ = normalize(params_test, param_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over test samples for \n",
    "- #### Quantiles \n",
    "- #### posterior mean differences \n",
    "- #### $D_{KL}$\n",
    "- #### credible intervals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# quantiles, dkl ratios and credible intervals for every dimension (2)\n",
    "dkl_ratios = np.zeros((3, ntest))\n",
    "\n",
    "qis = np.zeros_like(dkl_ratios)\n",
    "qis_hat = np.zeros_like(dkl_ratios)\n",
    "\n",
    "mus_hat = np.zeros_like(dkl_ratios)\n",
    "mus_exact = np.zeros_like(dkl_ratios)\n",
    "stds_hat = np.zeros_like(dkl_ratios)\n",
    "stds_exact = np.zeros_like(dkl_ratios)\n",
    "\n",
    "credible_intervals = np.arange(0.05, 1., 0.05)\n",
    "marginal_ci_counts = np.zeros((2, ntest, credible_intervals.size))\n",
    "marginal_ci_counts_hat = np.zeros((2, ntest, credible_intervals.size))\n",
    "\n",
    "covariances = []\n",
    "covariances_hat = []\n",
    "\n",
    "ms = []\n",
    "ms_hat = []\n",
    "ps = []\n",
    "ps_hat = []\n",
    "\n",
    "priors = [prior_k, prior_theta]\n",
    "joint_prior = JointGammaPrior(prior_k, prior_theta)\n",
    "# for every test sample \n",
    "fails = []\n",
    "\n",
    "with tqdm.tqdm(total=ntest) as pbar: \n",
    "    for ii, (thetao_i, sxo_i, xo_i) in enumerate(zip(params_test, sx_test_zt, x_test)): \n",
    "\n",
    "        # predict the posterior\n",
    "        post_hat_zt = model_params_mdn.predict(sxo_i.reshape(1, -1))\n",
    "        dd = post_hat_zt.get_dd_object()\n",
    "        # transform back to original parameter range\n",
    "        post_hat = post_hat_zt.ztrans_inv(param_norm[0], param_norm[1])\n",
    "        marginals_hat = post_hat.get_marginals()\n",
    "        \n",
    "        # the exact posterior \n",
    "        post_exact = NBExactPosterior(xo_i, prior_k, prior_theta)\n",
    "        post_exact.calculat_exact_posterior(theta_o=thetao_i, verbose=False, prec=1e-6, n_samples=300)\n",
    "        \n",
    "        marginals_exact = post_exact.get_marginals()\n",
    "        ps.append(post_exact)\n",
    "        ps_hat.append(post_hat)\n",
    "        ms.append(marginals_exact)\n",
    "        ms_hat.append(marginals_hat)\n",
    "       \n",
    "        try:\n",
    "            pbar.update()\n",
    "            # perform check for marginals         \n",
    "            for vi, (m, mhat, th) in enumerate(zip(marginals_exact, marginals_hat, thetao_i)):             \n",
    "                # means and std \n",
    "                # generate samples for estimating the mean and std\n",
    "                ss = m.gen(10000)\n",
    "                mus_exact[vi, ii], stds_exact[vi, ii] = m.mean, m.std\n",
    "                mus_hat[vi, ii], stds_hat[vi, ii] = mhat.mean, mhat.std\n",
    "\n",
    "                # quantiles \n",
    "                qis[vi, ii] = m.cdf(th)\n",
    "                qis_hat[vi, ii] = mhat.get_quantile(th)\n",
    "\n",
    "                # credible intervals\n",
    "                marginal_ci_counts[vi, ii, :] = m.get_credible_interval_counts(th, credible_intervals)\n",
    "                marginal_ci_counts_hat[vi, ii, :] = mhat.get_credible_interval_counts(th, credible_intervals)\n",
    "\n",
    "                # DKL \n",
    "                baseline = calculate_dkl_1D_scipy(m.pdf_array, priors[vi].pdf(m.support))\n",
    "                (dkl, err) = calculate_dkl_monte_carlo(np.array(ss), m.pdf, mhat.eval_numpy)\n",
    "                dkl_ratios[vi, ii] = dkl / baseline\n",
    "\n",
    "            # perform checks for joint \n",
    "            vi = 2\n",
    "\n",
    "            # quantiles \n",
    "            qis[vi, ii] = post_exact.cdf(thetao_i.reshape(1, -1))\n",
    "            qis_hat[vi, ii] = post_hat.get_quantile(thetao_i.reshape(1, -1))\n",
    "\n",
    "            # DKL \n",
    "            post_samples = post_exact.gen(20000)\n",
    "            (baseline, err) = calculate_dkl_monte_carlo(post_samples, post_exact.pdf, joint_prior.pdf)\n",
    "            dkl = calculate_dkl_monte_carlo(post_samples, post_exact.pdf, post_hat.eval_numpy)\n",
    "            (dkl_ratios[vi, ii], err) = dkl / baseline\n",
    "\n",
    "            # covariances\n",
    "            covariances.append(post_exact.cov)\n",
    "            covariances_hat.append(post_hat.get_covariance_matrix())     \n",
    "        except: \n",
    "            fails.append(ii)\n",
    "            continue\n",
    "fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save posterior checks results \n",
    "result_dict = dict(qis=qis, qis_hat=qis_hat, dkl_ratios=dkl_ratios,\n",
    "                  marginal_ci_counts=marginal_ci_counts, \n",
    "                  marginal_ci_counts_hat=marginal_ci_counts_hat, \n",
    "                  fails=fails, \n",
    "                  ntest=ntest, \n",
    "                  mus_exact=mus_exact, mus_hat=mus_hat, \n",
    "                  stds_exact=stds_exact, stds_hat=stds_hat, \n",
    "                  credible_intervals=credible_intervals, \n",
    "                  covariances=covariances, \n",
    "                  covariances_hat=covariances_hat, \n",
    "                  params_test=params_test, \n",
    "                  sx_test_zt=sx_test_zt, \n",
    "                  x_test=x_test, \n",
    "                  ps=ps, \n",
    "                  p_hats=ps_hat)\n",
    "\n",
    "fn = time_stamp + 'posterior_checks_results_NB_ntrain{}_ns{}_ntest{}'.format(ntrain, sample_size, ntest) + '.p'\n",
    "with open(os.path.join('../data', fn), 'wb') as outfile: \n",
    "    pickle.dump(result_dict, outfile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, pi in enumerate(fails): \n",
    "    p = ps[pi]\n",
    "    tho = params_test[pi]\n",
    "    print(tho)\n",
    "    p.calculated = False\n",
    "    p.calculat_exact_posterior(tho, n_samples=200, prec=1e-6)\n",
    "    margs = p.get_marginals()\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "#     plt.imshow(p.joint_pdf, origin='lower')\n",
    "    plt.plot(margs[0].support, margs[0].cdf_array)\n",
    "    plt.plot(margs[0].support, margs[0].pdf_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize means and variance to plot in same figure\n",
    "stds_exact_zt = (np.array(stds_exact).T - np.array(stds_exact).mean(axis=1)).T\n",
    "stds_hat_zt = (np.array(stds_hat).T - np.array(stds_hat).mean(axis=1)).T\n",
    "\n",
    "mus_exact_zt = (np.array(mus_exact).T - np.array(mus_exact).mean(axis=1)).T\n",
    "mus_hat_zt = (np.array(mus_hat).T - np.array(mus_hat).mean(axis=1)).T\n",
    "\n",
    "# exclude failed test params\n",
    "mask = np.logical_not(np.zeros(ntest))\n",
    "mask[fails] = False\n",
    "\n",
    "# exclude fails from marginal counts \n",
    "ci_probs = marginal_ci_counts[:, mask, :].mean(axis=1)\n",
    "ci_probs_hat = marginal_ci_counts_hat[:, mask, :].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig1, ax = plt.subplots(2, 3, figsize=(18, 8))\n",
    "labels = [r'$k$', r'$\\theta$']\n",
    "\n",
    "dkl_bins = np.linspace(0, 1, 20)\n",
    "\n",
    "for i in range(2):\n",
    "    line = np.linspace(mus_exact_zt[:, mask].min(), mus_exact_zt[:, mask].max(), 100)\n",
    "    ax[0, 0].scatter(x=mus_exact_zt[i, mask], y=mus_hat_zt[i, mask], label=labels[i] + r', ($\\mu$, $\\hat{\\mu}$)')\n",
    "    if i == 0: \n",
    "        ax[0, 0].plot(line, line, 'C2')\n",
    "        ax[0, 0].set_title('Marginal means')\n",
    "    ax[0, 0].legend()\n",
    "\n",
    "    line = np.linspace(stds_exact_zt[:, mask].min(), stds_exact_zt[:, mask].max(), 100)\n",
    "    ax[0, 1].scatter(x=stds_exact_zt[i, mask], y=stds_hat_zt[i, mask], label=labels[i] + r', ($\\sigma$, $\\hat{\\sigma}$)')\n",
    "    if i == 0: \n",
    "        ax[0, 1].plot(line, line, 'C2')        \n",
    "        ax[0, 1].set_title('Marginal variances')\n",
    "    ax[0, 1].legend()\n",
    "    \n",
    "    # DKL\n",
    "    n, dkl_bins, p = ax[0, 2].hist(dkl_ratios[i, mask], bins=dkl_bins, \n",
    "                                  alpha=0.6, \n",
    "                                  label=labels[i]);\n",
    "    ax[0, 2].set_title(r'$D_{KL}$ of marginals')\n",
    "    ax[i, 2].set_ylabel('count')\n",
    "    if i == 1: \n",
    "        ax[1, 2].set_xlabel(r'$D_{KL} / D_{KL}^{prior}$')\n",
    "        ax[1, 2].hist(dkl_ratios[2, mask], bins=dkl_bins, \n",
    "                                  alpha=0.6, \n",
    "                                  label='joint')\n",
    "        ax[1, 2].set_title(r'$D_{KL}$ of joint')\n",
    "        \n",
    "    ax[0, 2].legend(fontsize=15)\n",
    "    #                 label=r'$\\frac{D_{KL}(p(\\theta | x)||\\hat{p}(\\theta | x))}{ D_{KL}(p(\\theta | x)||p_{prior}(\\theta))}$', \n",
    "    \n",
    "    \n",
    "    n, bins = np.histogram(qis[i, mask], bins=credible_intervals)\n",
    "    sample_quantiles = np.cumsum(n / np.sum(n))\n",
    "    theo_quantiles = np.linspace(0, 1, len(n))\n",
    "    ax[1, 0].plot(theo_quantiles, sample_quantiles, 'x-', label=r'marginal ' + labels[i])\n",
    "    if i == 1:\n",
    "        ax[1, 0].plot(theo_quantiles, theo_quantiles)\n",
    "        ax[1, 0].grid()\n",
    "        ax[1, 0].set_title('Q-Q plot')\n",
    "    ax[1, 0].legend()\n",
    "    ax[1, 0].set_ylabel('empirical quantile')\n",
    "    ax[1, 0].set_xlabel(r'quantile of $U(0, 1)$')\n",
    "    \n",
    "    ax[1, 1].plot(credible_intervals, ci_probs_hat[i, ], 'x-', label=r'marginal ' + labels[i])\n",
    "    if i==1:\n",
    "        ax[1, 1].plot(credible_intervals, credible_intervals, '-')\n",
    "        ax[1, 1].set_ylabel('relative frequency')\n",
    "        ax[1, 1].set_xlabel('credible interval')\n",
    "        ax[1, 1].grid()\n",
    "        ax[1, 1].set_title('Credible intervals')\n",
    "    ax[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = time_stamp + 'posterior_checks_marginals_NB_ntrain{}_nsamples{}_ntest{}.png'.format(int(ntrain), \n",
    "                                                                                         int(sample_size), \n",
    "                                                                                        int(ntest))\n",
    "fig1.savefig(os.path.join('../figures', fn), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(ph.gen(10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nt = mask.sum()\n",
    "ev_means = np.zeros((2, mask.sum()))\n",
    "ev_stds = np.zeros((2, nt))\n",
    "ev_meansh = np.zeros((2, nt))\n",
    "ev_stdsh = np.zeros((2, nt))\n",
    "\n",
    "evs = np.zeros((2, ntest))\n",
    "evsh = np.zeros((2, ntest))\n",
    "ii = 0\n",
    "\n",
    "for i, (p, ph) in enumerate(zip(ps, ps_hat)): \n",
    "    \n",
    "    if i not in fails: \n",
    "        # get samples \n",
    "        ns = 1000\n",
    "        s = np.array(p.samples)[:ns]\n",
    "        sh = np.array(ph.gen(ns))\n",
    "        assert(sh.shape == (ns, 2)), '{}, {}'.format(sh.shape, ph.n_components)\n",
    "\n",
    "        # get evs \n",
    "        evals, evecs = np.linalg.eig(p.cov)    \n",
    "        evalsh, evecsh = np.linalg.eig(ph.get_covariance_matrix())\n",
    "\n",
    "    #     print(evals, evalsh)\n",
    "    #     print(evecs, evecsh)\n",
    "\n",
    "        # project the samples \n",
    "        sp1 = s.dot(evecs[:, 0])\n",
    "        sph1 = sh.dot(evecsh[:, 0])\n",
    "        sp2 = s.dot(evecs[:, 1])\n",
    "        sph2 = sh.dot(evecsh[:, 1])\n",
    "\n",
    "        # save eigenvectors \n",
    "        evs[:, ii] = evecs[0, :]\n",
    "        evsh[:, ii] = evecsh[0, :]\n",
    "\n",
    "        # save means and stds \n",
    "        ev_means[0, ii] = sp1.mean()\n",
    "        ev_means[1, ii] = sp2.mean()\n",
    "        ev_stds[0, ii] = sp1.std()\n",
    "        ev_stds[1, ii] = sp2.std()\n",
    "        ev_meansh[0, ii] = sph1.mean()\n",
    "        ev_meansh[1, ii] = sph2.mean()\n",
    "        ev_stdsh[0, ii] = sph1.std()\n",
    "        ev_stdsh[1, ii] = sph2.std()\n",
    "        \n",
    "        ii += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4)\n",
    "\n",
    "plt.suptitle('Means and stds of samples along eigenvector marginals', fontsize=20)\n",
    "ax[0].scatter(ev_means[0, ], ev_meansh[0, ], label='means, largest EV')\n",
    "ax[0].set_xlabel('exact')\n",
    "ax[0].set_ylabel('predicted')\n",
    "line = np.linspace(ev_means[0, ].min(), ev_means[0, ].max(), 100)\n",
    "ax[0].plot(line, line, color='C1')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[2].scatter(ev_means[1, ], ev_meansh[1, ], label='means, smallest EV')\n",
    "ax[2].set_xlabel('exact')\n",
    "line = np.linspace(ev_means[1, ].min(), ev_means[1, ].max(), 100)\n",
    "ax[2].plot(line, line, color='C1')\n",
    "ax[2].legend()\n",
    "\n",
    "ax[1].scatter(ev_stds[0, ], ev_stdsh[0, ], label='stds, largest EV')\n",
    "line = np.linspace(ev_stds[0, ].min(), ev_stds[0, ].max(), 100)\n",
    "ax[1].plot(line, line, color='C1')\n",
    "ax[1].set_xlabel('exact')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[3].scatter(ev_stds[1, ], ev_stdsh[1, ], label='stds, smallest EV')\n",
    "line = np.linspace(ev_stds[1, ].min(), ev_stds[1, ].max(), 100)\n",
    "ax[3].plot(line, line, color='C1')\n",
    "ax[3].set_xlabel('exact')\n",
    "ax[3].legend();\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(p.ks, p.thetas)\n",
    "pos = np.vstack((x.flatten(), y.flatten())).T\n",
    "pdfh = ph.eval_numpy(pos).reshape(p.ks.size, p.thetas.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(18, 8))\n",
    "\n",
    "x, y = np.meshgrid(p.ks, p.thetas)\n",
    "pos = np.hstack((x, y))\n",
    "\n",
    "ki = 200 \n",
    "thi = 150\n",
    "ax[0, 0].imshow(p.joint_pdf[:ki, :thi], origin='lower', extent=[p.thetas[:thi].min(), p.thetas[:thi].max(), \n",
    "                                                                p.ks[:ki].min(), p.ks[:ki].max()], \n",
    "                aspect='auto')\n",
    "ax[0, 0].set_title('Numerical true posterior')\n",
    "\n",
    "ax[0, 1].imshow(pdfh.T[:ki, :thi], origin='lower', extent=[p.thetas[:thi].min(), p.thetas[:thi].max(), \n",
    "                                                                p.ks[:ki].min(), p.ks[:ki].max()], \n",
    "                aspect='auto')\n",
    "ax[0, 1].set_title('Predicted posterior')\n",
    "\n",
    "n, bins, patch = ax[1, 0].hist(sp1, alpha=0.6, label='true', bins='auto');\n",
    "ax[1, 0].hist(sph1, alpha=0.6, label='predicted', bins='auto');\n",
    "ax[1, 0].set_title('Samples along largest eigenvector')\n",
    "ax[1, 0].legend()\n",
    "\n",
    "n, bins, patch = ax[1, 1].hist(sp2, alpha=0.6, label='true, small EV', bins='auto');\n",
    "ax[1, 1].hist(sph2, alpha=0.6, label='predicted, small EV', bins='auto');\n",
    "ax[1, 1].set_title('Samples along smallest eigenvector');\n",
    "ax[1, 1].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].set_title('Credible intervals')\n",
    "ax[0].plot(credible_intervals, ci_probs_hat[0, ], 'x-', label=r'marginal $\\hat{p}(k | x)$')\n",
    "ax[0].plot(credible_intervals, ci_probs_hat[1, ], 'x-', label=r'marginal $\\hat{p}(\\theta | x)$')\n",
    "# ax[0].plot(credible_intervals, ci_probs[0, ], 'x-', label=r'marginal $p(k | x)$')\n",
    "# ax[0].plot(credible_intervals, ci_probs[1, ], 'x-', label=r'marginal $p(\\theta | x)$')\n",
    "ax[0].plot(credible_intervals, credible_intervals, '-', label='identity')\n",
    "ax[0].legend()\n",
    "\n",
    "theo_quantiles = \n",
    "ax[1].plot(credible_intervals, cr_probs, 'x-', label='joint')\n",
    "ax[1].set_title('Joint')\n",
    "ax[1].plot(credible_intervals, credible_intervals, '-', label='identity')\n",
    "ax[1].legend();\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig2, ax = plt.subplots(2, 3, figsize=(18, 10), sharex=True, sharey='col')\n",
    "labels = ['k', 'theta']\n",
    "for i in range(2):\n",
    "    (stats, kst_p) = scipy.stats.kstest(qis[i, ], cdf='uniform')\n",
    "    n, bins, patches = ax[i, 0].hist(qis[i, ], bins=20, label='K-S test, p={:1.3}'.format(kst_p))\n",
    "    ax[i, 0].set_title('Posterior quantile distribution ' + labels[i])\n",
    "    ax[i, 0].set_xlabel('quantile')\n",
    "    ax[i, 0].set_ylabel('counts')\n",
    "    ax[i, 0].legend()\n",
    "\n",
    "    ax[i, 1].set_title('Posterior quantile Q-Q plot ' + labels[i])\n",
    "    sample_quantiles = np.cumsum(n / np.sum(n))\n",
    "    theo_quantiles = np.cumsum(np.diff(bins))\n",
    "    \n",
    "    ax[i, 1].plot(theo_quantiles, sample_quantiles, 'x-', label='empirical')\n",
    "    ax[i, 1].plot(theo_quantiles, theo_quantiles, label='identity line')\n",
    "    ax[i, 1].set_ylabel('empirical quantile')\n",
    "    ax[i, 1].set_xlabel(r'quantile of $U(0, 1)$')\n",
    "    ax[i, 1].legend()\n",
    "    ax[i, 1].grid();\n",
    "\n",
    "    ax[i, 2].set_title('Posterior credible intervals ' + labels[i])\n",
    "    \n",
    "    ax[i, 2].plot(credible_intervals, ci_probs[i, ], 'x-', label='empirical')\n",
    "    ax[i, 2].plot(credible_intervals, credible_intervals, '-', label='identity line')\n",
    "    ax[i, 2].set_ylabel('relative frequency')\n",
    "    ax[i, 2].set_xlabel('credible interval')\n",
    "    ax[i, 2].legend()\n",
    "    ax[i, 2].grid();\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = time_stamp + 'posterior_checks_2_k2_{}NB.png'.format(int(k2))\n",
    "fig2.savefig(os.path.join('../figures', fn), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mackelab]",
   "language": "python",
   "name": "conda-env-mackelab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
