{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os \n",
    "import pickle\n",
    "import sys \n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "sys.path.append('../../')\n",
    "from model_comparison.utils import *\n",
    "from model_comparison.mdns import *\n",
    "from model_comparison.models import PoissonModel, NegativeBinomialModel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl_params = {'legend.fontsize': 15,\n",
    "              'legend.frameon': False,\n",
    "                      'axes.titlesize': 20,\n",
    "                      'axes.labelsize': 17,\n",
    "                      'xtick.labelsize': 12,\n",
    "                      'ytick.labelsize': 12,\n",
    "             'figure.figsize' : (18, 5)}\n",
    "\n",
    "mpl.rcParams.update(mpl_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and train NB posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = '../data/'\n",
    "fn = '201803220946_toy_example_results_N100000M10_k21.0.p'\n",
    "time_stamp = fn[:fn.find('_')]\n",
    "\n",
    "with open(os.path.join(folder, fn), 'rb') as f: \n",
    "    d = pickle.load(f)\n",
    "    \n",
    "# set the seed for generating new test data \n",
    "seed = 5\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# priors \n",
    "d_model = d['model_post']\n",
    "sample_size = d_model['sample_size']\n",
    "k1, k2, k3 = d_model['k1'], d_model['k2'], d_model['k3']\n",
    "theta1, theta2, theta3 = d_model['theta1'], d_model['theta2'], d_model['theta3']\n",
    "\n",
    "prior_lambda = scipy.stats.gamma(a=k1, scale=theta1)\n",
    "prior_k = scipy.stats.gamma(a=k2, scale=theta2)\n",
    "prior_theta = scipy.stats.gamma(a=k3, scale=theta3)\n",
    "\n",
    "model_nb = NegativeBinomialModel(sample_size=sample_size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate training data \n",
    "ntrain = 100000\n",
    "params_train = np.vstack((prior_k.rvs(size=ntrain), prior_theta.rvs(size=ntrain))).T\n",
    "x_train = model_nb.gen(params_train)\n",
    "\n",
    "sx_train = calculate_stats_toy_examples(x_train)\n",
    "sx_train_zt, data_norm = normalize(sx_train)\n",
    "params_train_zt, param_norm = normalize(params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the posterior network \n",
    "# define a network to approximate the posterior with a MoG \n",
    "model_params_mdn = MultivariateMogMDN(ndim_input=2, ndim_output=2, n_hidden_units=10, \n",
    "                                      n_hidden_layers=1, n_components=2)\n",
    "optimizer = torch.optim.Adam(model_params_mdn.parameters(), lr=0.01)\n",
    "trainer = Trainer(model_params_mdn, optimizer, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trace = trainer.train(sx_train_zt, params_train_zt, n_epochs=100, n_minibatch=int(sx_train.shape[0] / 100))\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.plot(loss_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample new test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntest = 1000\n",
    "params_test = np.vstack((prior_k.rvs(size=ntest), prior_theta.rvs(size=ntest))).T\n",
    "x_test = model_nb.gen(params_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sx_test = calculate_stats_toy_examples(x_test)\n",
    "sx_test_zt, _ = normalize(sx_test, data_norm)\n",
    "params_test_zt, _ = normalize(params_test, param_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over test samples for \n",
    "- #### Quantiles \n",
    "- #### posterior mean differences \n",
    "- #### $D_{KL}$\n",
    "- #### credible intervals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ci_count(m, theta_o, ints): \n",
    "    q = m.get_quantile(theta_o) \n",
    "    # q mass lies below th\n",
    "    if q > 0.5: \n",
    "        # how much mass is above times 2 \n",
    "        ci = 1 - 2 * (1 - q)\n",
    "    else: \n",
    "        # how much mass is below, times 2 \n",
    "        ci = 1 - 2 * q\n",
    "    counts = np.ones_like(ints) * (ints >= ci)\n",
    "    return counts\n",
    "\n",
    "def cr_count(post, theta_o, ints):\n",
    "    q = post.get_quantile(theta_o.reshape(1, -1))\n",
    "    if q > 0.5: \n",
    "        # how much mass is above times 2 \n",
    "        ci = 1 - 2 * (1 - q)\n",
    "    else: \n",
    "        # how much mass is below, times 2 \n",
    "        ci = 1 - 2 * q\n",
    "    counts = np.ones_like(ints) * (ints > ci)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus_hat = []\n",
    "mus_exact = []\n",
    "stds_hat = []\n",
    "stds_exact = []\n",
    "\n",
    "# quantiles, dkl ratios and credible intervals for every dimension (2)\n",
    "dkl_ratios = np.zeros((2, ntest))\n",
    "qis = np.zeros_like(dkl_ratios)\n",
    "credible_intervals = np.arange(0.05, 1., 0.05)\n",
    "marginal_ci_counts = np.zeros((2, credible_intervals.size))\n",
    "joint_cr_counts = np.zeros_like(credible_intervals)\n",
    "\n",
    "# for every test sample \n",
    "with tqdm.tqdm(total=ntest) as pbar: \n",
    "    for ii, (thetao_i, sxo_i, xo_i) in enumerate(zip(params_test, sx_test_zt, x_test)): \n",
    "\n",
    "        # predict the posterior\n",
    "        post_hat = model_params_mdn.predict(sxo_i.reshape(1, -1))\n",
    "        # get dd object \n",
    "#         post_hat_dd = post_hat.get_dd_object()\n",
    "#         # transform to original parameter range \n",
    "#         post_hat_or = post_hat_dd.ztrans_inv(param_norm[0], param_norm[1])\n",
    "        \n",
    "#         # get the mean \n",
    "#         mus_hat.append(post_hat_or.mean)\n",
    "#         stds_hat.append(post_hat_or.std)\n",
    "\n",
    "        # get the mean of the exact posterior \n",
    "#         post_exact = model_nb.get_exact_posterior(xo_i, prior_k, prior_theta)\n",
    "#         mus_exact.append(post_exact.mean)\n",
    "#         stds_exact.append(post_exact.std)\n",
    "        \n",
    "        # for every variable, look at the marginal\n",
    "        # get quantile of theta_o, for each parameter component separately\n",
    "        thetao_i_zt, _ = normalize(thetao_i, param_norm)\n",
    "        marginals = post_hat.get_marginals()\n",
    "        \n",
    "        joint_cr_counts += cr_count(post_hat, thetao_i_zt, credible_intervals)\n",
    "    \n",
    "        for vi, (m, th) in enumerate(zip(marginals, thetao_i_zt)): \n",
    "            qis[vi, ii] = m.get_quantile(th)\n",
    "            marginal_ci_counts[vi, :] += ci_count(m, th, credible_intervals)\n",
    "#             success_counts[vi, :] += calculate_credible_interval_counts(m, theta_o=th, \n",
    "#                                                                           intervals=credible_intervals)\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_probs = marginal_ci_counts / ntest\n",
    "ci_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_probs = joint_cr_counts / ntest\n",
    "cr_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].plot(credible_intervals, ci_probs[0, ], 'x-', label='marginal k')\n",
    "ax[0].set_title('marginal k')\n",
    "ax[1].plot(credible_intervals, ci_probs[1, ], 'x-', label='marginal theta')\n",
    "ax[1].set_title('marginal theta')\n",
    "ax[2].plot(credible_intervals, cr_probs, 'x-', label='joint')\n",
    "ax[2].set_title('joint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax = plt.subplots(2, 3, figsize=(18, 10), sharex=True, sharey='col')\n",
    "labels = ['k', 'theta']\n",
    "for i in range(2):\n",
    "    (stats, kst_p) = scipy.stats.kstest(qis[i, ], cdf='uniform')\n",
    "    n, bins, patches = ax[i, 0].hist(qis[i, ], bins=20, label='K-S test, p={:1.3}'.format(kst_p))\n",
    "    ax[i, 0].set_title('Posterior quantile distribution ' + labels[i])\n",
    "    ax[i, 0].set_xlabel('quantile')\n",
    "    ax[i, 0].set_ylabel('counts')\n",
    "    ax[i, 0].legend()\n",
    "\n",
    "    ax[i, 1].set_title('Posterior quantile Q-Q plot ' + labels[i])\n",
    "    sample_quantiles = np.cumsum(n / np.sum(n))\n",
    "    theo_quantiles = np.cumsum(np.diff(bins))\n",
    "    \n",
    "    ax[i, 1].plot(theo_quantiles, sample_quantiles, 'x-', label='empirical')\n",
    "    ax[i, 1].plot(theo_quantiles, theo_quantiles, label='identity line')\n",
    "    ax[i, 1].set_ylabel('empirical quantile')\n",
    "    ax[i, 1].set_xlabel(r'quantile of $U(0, 1)$')\n",
    "    ax[i, 1].legend()\n",
    "    ax[i, 1].grid();\n",
    "\n",
    "    ax[i, 2].set_title('Posterior credible intervals ' + labels[i])\n",
    "    \n",
    "    ax[i, 2].plot(credible_intervals, ci_probs[i, ], 'x-', label='empirical')\n",
    "    ax[i, 2].plot(credible_intervals, credible_intervals, '-', label='identity line')\n",
    "    ax[i, 2].set_ylabel('relative frequency')\n",
    "    ax[i, 2].set_xlabel('credible interval')\n",
    "    ax[i, 2].legend()\n",
    "    ax[i, 2].grid();\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = time_stamp + 'posterior_checks_2_k2_{}NB.png'.format(int(k2))\n",
    "fig2.savefig(os.path.join('../figures', fn), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mackelab]",
   "language": "python",
   "name": "conda-env-mackelab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
