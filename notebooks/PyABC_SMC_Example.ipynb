{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from pyabc import (ABCSMC, RV,\n",
    "                   PercentileDistanceFunction, DistanceFunction, sampler)\n",
    "from pyabc import Distribution as abcDis\n",
    "\n",
    "import sys \n",
    "sys.path.append('../../')\n",
    "from model_comparison.utils import *\n",
    "from model_comparison.mdns import *\n",
    "from model_comparison.models import PoissonModel, NegativeBinomialModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "sample_size = 10\n",
    "ntrain = int(1e6)\n",
    "ntest = 200\n",
    "\n",
    "k2 = 2.\n",
    "theta2 = 1.0\n",
    "\n",
    "k3 = 2.\n",
    "theta3 = 2. \n",
    "\n",
    "# then the scale of the Gamma prior for the Poisson is given by\n",
    "theta1 = 2.0\n",
    "k1 = (k2 * theta2 * k3 * theta3) / theta1\n",
    "print(k1)\n",
    "\n",
    "\n",
    "model_poisson = PoissonModel(sample_size=sample_size, seed=seed, n_workers=1)\n",
    "model_nb = NegativeBinomialModel(sample_size=sample_size, seed=seed, n_workers=1)\n",
    "# from Gamma prior for Poisson \n",
    "prior_lam = scipy.stats.gamma(a=k1, scale=theta1)\n",
    "prior_k = scipy.stats.gamma(a=k2, scale=theta2)\n",
    "prior_theta = scipy.stats.gamma(a=k3, scale=theta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the models need to be defined in this way\n",
    "def model_1(parameters): \n",
    "    x = model_poisson.gen([parameters.lam])\n",
    "    return {'y': np.array([x.mean(), x.std()])}\n",
    "\n",
    "def model_2(parameters): \n",
    "    x = model_nb.gen([[parameters.k, parameters.theta]])\n",
    "    return {'y': np.array([x.mean(), x.std()])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there is a wrapper function around scipy.stats. functions for defining the prior \n",
    "# type: name of the scipy stats function \n",
    "# kwargs: the kwards of that functions, e.g., kwargs of scipy.stats.gamma\n",
    "prior1 = abcDis.from_dictionary_of_dictionaries(dict(lam={'type': 'gamma', 'kwargs': {'a':k1, 'scale': theta1}}))\n",
    "\n",
    "prior2 = abcDis.from_dictionary_of_dictionaries(dict(k={'type': 'gamma', 'kwargs': {'a':k2, 'scale': theta2}}, \n",
    "                                                     theta={'type': 'gamma', 'kwargs': {'a':k3, 'scale': theta3}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define two models, but they are identical so far\n",
    "models = [model_1, model_2]\n",
    "\n",
    "# However, our models' priors are not the same.\n",
    "# Their mean differs.\n",
    "parameter_priors = [prior1, prior2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an own distance function: mean squared distance error \n",
    "class MyDist(DistanceFunction): \n",
    "    \n",
    "    def __call__(self, x, y): \n",
    "        return np.power(x['y'] - y['y'], 2).mean()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We plug all the ABC options together\n",
    "abc = ABCSMC(\n",
    "    models, parameter_priors,\n",
    "    MyDist(), sampler=sampler.SingleCoreSampler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_observed is the important piece here: our actual observation.\n",
    "\n",
    "# set ground truth here \n",
    "# xo = model_poisson.gen([2])\n",
    "xo = model_nb.gen([[2, 3]])\n",
    "y_observed = [xo.mean(), xo.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we define where to store the results\n",
    "db_path = (\"sqlite:///\" +\n",
    "           os.path.join(tempfile.gettempdir(), \"test.db\"))\n",
    "abc_id = abc.new(db_path, {\"y\": y_observed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ABC-SMC run ID:\", abc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = abc.run(minimum_epsilon=0.05, max_nr_populations=4, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model probabililties\n",
    "model_probabilities = history.get_model_probabilities()\n",
    "model_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_probabilities[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
