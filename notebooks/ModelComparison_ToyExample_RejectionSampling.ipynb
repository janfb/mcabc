{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import time\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyabc import (ABCSMC, RV,\n",
    "                   PercentileDistanceFunction, DistanceFunction, sampler)\n",
    "from pyabc import Distribution as abcDis\n",
    "\n",
    "import sys \n",
    "sys.path.append('../../')\n",
    "from model_comparison.utils import *\n",
    "from model_comparison.mdns import *\n",
    "from model_comparison.models import PoissonModel, NegativeBinomialModel\n",
    "\n",
    "from delfi.distribution.mixture import MoG\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl_params = {'legend.fontsize': 14,\n",
    "              'legend.frameon': False,\n",
    "                      'axes.titlesize': 20,\n",
    "                      'axes.labelsize': 17,\n",
    "                      'xtick.labelsize': 12,\n",
    "                      'ytick.labelsize': 12,\n",
    "             'figure.figsize' : (18, 5)}\n",
    "\n",
    "mpl.rcParams.update(mpl_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 3\n",
    "rng = np.random.RandomState(seed=seed)\n",
    "time_stamp = time.strftime('%Y%m%d%H%M_')\n",
    "figure_folder = '../figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10\n",
    "ntest = 500\n",
    "\n",
    "k2 = 2.\n",
    "theta2 = 1.0\n",
    "\n",
    "k3 = 2.\n",
    "theta3 = 2. \n",
    "\n",
    "# then the scale of the Gamma prior for the Poisson is given by\n",
    "theta1 = 2.0\n",
    "k1 = (k2 * theta2 * k3 * theta3) / theta1\n",
    "print(k1)\n",
    "\n",
    "\n",
    "model_poisson = PoissonModel(sample_size=sample_size, seed=seed, n_workers=1)\n",
    "model_nb = NegativeBinomialModel(sample_size=sample_size, seed=seed, n_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from Gamma prior for Poisson \n",
    "prior_lam = scipy.stats.gamma(a=k1, scale=theta1)\n",
    "prior_k = scipy.stats.gamma(a=k2, scale=theta2)\n",
    "prior_theta = scipy.stats.gamma(a=k3, scale=theta3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = ntest\n",
    "params_poi_test = prior_lam.rvs(size=int(n / 2))\n",
    "params_nb_test = np.vstack((prior_k.rvs(size=int(n / 2)), \n",
    "                       prior_theta.rvs(size=int(n / 2)))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_poi_test = model_poisson.gen(params_poi_test)\n",
    "data_nb_test = model_nb.gen(params_nb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_poi_test = np.array([data_poi_test.mean(axis=1), data_poi_test.var(axis=1)]).T\n",
    "stats_nb_test = np.array([data_nb_test.mean(axis=1), data_nb_test.var(axis=1)]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyABC SMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models oin pyabc style \n",
    "def model_1(parameters): \n",
    "    x = model_poisson.gen([parameters.lam])\n",
    "    return {'y': np.array([x.mean(), x.var()])}\n",
    "\n",
    "def model_2(parameters): \n",
    "    x = model_nb.gen([[parameters.k, parameters.theta]])\n",
    "    return {'y': np.array([x.mean(), x.var()])}\n",
    "\n",
    "# priors\n",
    "prior1 = abcDis.from_dictionary_of_dictionaries(dict(lam={'type': 'gamma', 'kwargs': {'a':k1, 'scale': theta1}}))\n",
    "\n",
    "prior2 = abcDis.from_dictionary_of_dictionaries(dict(k={'type': 'gamma', 'kwargs': {'a':k2, 'scale': theta2}}, \n",
    "                                                     theta={'type': 'gamma', 'kwargs': {'a':k3, 'scale': theta3}}))\n",
    "\n",
    "models = [model_1, model_2]\n",
    "parameter_priors = [prior1, prior2]\n",
    "\n",
    "class MyDist(DistanceFunction): \n",
    "    \n",
    "    def __call__(self, x, y): \n",
    "        return np.power(x['y'] - y['y'], 2).mean()      \n",
    "    \n",
    "    \n",
    "class MyModelPrior(RV): \n",
    "    \n",
    "    def rvs(self, *args, **kwargs):\n",
    "        model_idx_vector = self.distribution.rvs(*args, **kwargs)[0]\n",
    "        return np.where(model_idx_vector)[0][0]\n",
    "    \n",
    "    def pmf(self, x, *args, **kwargs):\n",
    "        xv = [0, 0]\n",
    "        xv[x] = 1\n",
    "        return self.distribution.pmf(xv, *args, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMC with single round = rejection sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.vstack((stats_poi_test, stats_nb_test))\n",
    "phat_rej = np.zeros((ntest, 2))\n",
    "model_prior = MyModelPrior.from_dictionary({'type': 'multinomial', 'kwargs': {'n': 1, 'p': [0.5, 0.5]}})\n",
    "\n",
    "for ii in tqdm.tqdm(range(ntest)): \n",
    "    sxo = test_set[ii, ]\n",
    "\n",
    "    # We plug all the ABC options together\n",
    "    abc = ABCSMC(\n",
    "        models, parameter_priors, MyDist(), model_prior=model_prior,\n",
    "         sampler=sampler.SingleCoreSampler(), population_size=75)\n",
    "\n",
    "    # and we define where to store the results\n",
    "    db_path = (\"sqlite:///\" +\n",
    "               os.path.join(tempfile.gettempdir(), \"test.db\"))\n",
    "    abc_id = abc.new(db_path, {\"y\": sxo})\n",
    "    history = abc.run(minimum_epsilon=0.05, max_nr_populations=1)\n",
    "    model_probabilities = history.get_model_probabilities()\n",
    "    print(history.total_nr_simulations)\n",
    "    ppoi = model_probabilities[0][0]\n",
    "    phat_rej[ii, 0] = ppoi\n",
    "    phat_rej[ii, 1] = 1 - ppoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMC with multiple round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.vstack((stats_poi_test, stats_nb_test))\n",
    "phat_smc = np.zeros((ntest, 2))\n",
    "n_rounds = 3\n",
    "n_simulations = 0\n",
    "\n",
    "for ii in tqdm.tqdm(range(ntest)): \n",
    "    sxo = test_set[ii, ]\n",
    "\n",
    "    # We plug all the ABC options together\n",
    "    abc = ABCSMC(\n",
    "        models, parameter_priors,\n",
    "        MyDist(), population_size=20)\n",
    "\n",
    "    # and we define where to store the results\n",
    "    db_path = (\"sqlite:///\" +\n",
    "               os.path.join(tempfile.gettempdir(), \"test.db\"))\n",
    "    abc_id = abc.new(db_path, {\"y\": sxo})\n",
    "    history = abc.run(minimum_epsilon=0.05, max_nr_populations=n_rounds)\n",
    "    model_probabilities = history.get_model_probabilities()\n",
    "    n_simulations += history.total_nr_simulations\n",
    "    print(n_simulations)\n",
    "    ppoi = model_probabilities[0][n_rounds - 1]\n",
    "    phat_smc[ii, 0] = ppoi\n",
    "    phat_smc[ii, 1] = 1 - ppoi\n",
    "    print(model_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data sets with similar number of samples as used by SMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = n_simulations\n",
    "params_poi = prior_lam.rvs(size=int(n / 2))\n",
    "params_nb = np.vstack((prior_k.rvs(size=int(n / 2)), \n",
    "                       prior_theta.rvs(size=int(n / 2)))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_poi = model_poisson.gen(params_poi)\n",
    "data_nb = model_nb.gen(params_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_poi = np.array([data_poi.mean(axis=1), data_poi.var(axis=1)]).T\n",
    "stats_nb = np.array([data_nb.mean(axis=1), data_nb.var(axis=1)]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate true posterior probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest = np.vstack((data_poi_test, data_nb_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppoi_exact = []\n",
    "for xi in tqdm.tqdm(xtest): \n",
    "    nb_logevi = calculate_nb_evidence(xi, k2, theta2, k3, theta3, log=True)\n",
    "    poi_logevi = poisson_evidence(xi, k=k1, theta=theta1, log=True)\n",
    "    ppoi_exact.append(calculate_pprob_from_evidences(np.exp(poi_logevi), np.exp(nb_logevi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do density estimation with same training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle and set up model index target vector \n",
    "x_all = np.vstack((data_poi, data_nb))\n",
    "\n",
    "# define model indices\n",
    "m_all = np.hstack((np.zeros(data_poi.shape[0]), np.ones(data_nb.shape[0]))).squeeze().astype(int).tolist()\n",
    "\n",
    "# get shuffled indices \n",
    "# shuffle_indices = np.arange(n)\n",
    "# np.random.shuffle(shuffle_indices)\n",
    "\n",
    "x, x_test = x_all[:ntrain, :], x_all[ntrain:, :]\n",
    "m, m_test = m_all[:ntrain], m_all[ntrain:]\n",
    "\n",
    "# calculate summary stats\n",
    "sx = calculate_stats_toy_examples(x)\n",
    "# sx_test = calculate_stats_toy_examples(xtest)\n",
    "# use training norm to normalize test data \n",
    "sx_zt, training_norm = normalize(sx)\n",
    "# sx_test_zt, training_norm = normalize(sx_test, training_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationMDN(n_input=2, n_hidden_units=10, n_hidden_layers=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "trainer = Trainer(model, optimizer, verbose=True, classification=True)\n",
    "\n",
    "n_epochs = 10\n",
    "n_minibatch = int(ntrain / 100)\n",
    "\n",
    "# train with training data\n",
    "loss_trace = trainer.train(sx_zt, m, n_epochs=n_epochs, n_minibatch=n_minibatch)\n",
    "plt.plot(loss_trace)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = np.arange(0.1, 1., 0.2)\n",
    "post_probs_mean = np.zeros_like(prior_probs)\n",
    "sx_test_m1 = stats_poi_test[:100]\n",
    "sx_test_m2 = stats_nb_test[:100]\n",
    "n_rounds = 3\n",
    "\n",
    "for ii, pp in enumerate(prior_probs): \n",
    "    idx = int(pp * 100)\n",
    "    # up to idx for m1\n",
    "    d1 = sx_test_m1[:idx, ]\n",
    "    # from idx to end for m2\n",
    "    d2 = sx_test_m2[idx:, ]\n",
    "    test_set = np.vstack((d1, d2))\n",
    "    model_prior = MyModelPrior.from_dictionary({'type': 'multinomial', 'kwargs': {'n': 1, 'p': [pp, 1 - pp]}})\n",
    "    \n",
    "    # rejection sampling \n",
    "    ppoi = np.zeros(test_set.shape[0])\n",
    "    n_simulations = 0\n",
    "    for jj in tqdm.tqdm(range(test_set.shape[0])): \n",
    "        sxo = test_set[jj, ]\n",
    "\n",
    "        # We plug all the ABC options together\n",
    "        abc = ABCSMC(\n",
    "            models, parameter_priors, \n",
    "            MyDist(), model_prior=model_prior)\n",
    "\n",
    "        # and we define where to store the results\n",
    "        db_path = (\"sqlite:///\" +\n",
    "                   os.path.join(tempfile.gettempdir(), \"test.db\"))\n",
    "        abc_id = abc.new(db_path, {\"y\": sxo})\n",
    "        history = abc.run(minimum_epsilon=0.05, max_nr_populations=n_rounds)\n",
    "        model_probabilities = history.get_model_probabilities().as_matrix()\n",
    "        n_simulations += history.total_nr_simulations\n",
    "        try: \n",
    "            ppoi[jj] = model_probabilities[0, model_probabilities.shape[0] - 1]\n",
    "        except:\n",
    "            ppoi[jj] = model_probabilities[model_probabilities.shape[0] - 1, 0]\n",
    "\n",
    "    print(n_simulations)\n",
    "       \n",
    "    post_probs_mean[ii] = ppoi.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_poi.shape, data_poi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx_test_m1 = stats_poi_test[:100]\n",
    "sx_test_m2 = stats_nb_test[:100]\n",
    "prior_probs = np.arange(0.1, 1., 0.1)\n",
    "post_probs_mean_de = np.zeros_like(prior_probs)\n",
    "\n",
    "for ii, pp in enumerate(prior_probs): \n",
    "    idx = int(pp * 100)\n",
    "    # up to idx for m1\n",
    "    d1 = sx_test_m1[:idx, ]\n",
    "    # from idx to end for m2\n",
    "    d2 = sx_test_m2[idx:, ]\n",
    "    test_set = np.vstack((d1, d2))\n",
    "    \n",
    "    # learn new abc model with given prior on training set \n",
    "    loop_model = ClassificationMDN(n_input=2, n_hidden_units=10, n_hidden_layers=1)\n",
    "    optimizer = torch.optim.Adam(loop_model.parameters(), lr=0.01)\n",
    "    trainer = Trainer(loop_model, optimizer, verbose=True, classification=True)\n",
    "\n",
    "    # train with training data\n",
    "    ntrain = stats_poi.shape[0]  # training size \n",
    "    training_set_idx = int(pp * ntrain)  # set prior index \n",
    "    sx_loop = np.vstack((stats_poi[:training_set_idx, ], stats_nb[training_set_idx:, ]))\n",
    "    m_loop = np.hstack((np.zeros(training_set_idx), np.ones(ntrain - training_set_idx))).astype(int).tolist()\n",
    "    \n",
    "    sx_loop_zt, loop_norm = normalize(sx_loop)\n",
    "\n",
    "    n_epochs = 10\n",
    "    n_minibatch = int(ntrain / 100)\n",
    "\n",
    "    loss_trace = trainer.train(sx_loop_zt, m_loop, n_epochs=n_epochs, n_minibatch=n_minibatch)\n",
    "    # predict with abc model \n",
    "    test_data_zt, _ = normalize(test_set, loop_norm)\n",
    "    p = loop_model.predict(test_data_zt)[:, 0]\n",
    "    post_probs_mean_de[ii] = p.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(.1, 1., .2), post_probs_mean, 'o-')\n",
    "plt.plot(prior_probs, post_probs_mean_de, 'o-')\n",
    "plt.plot(prior_probs, prior_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sx_test = np.vstack((stats_poi_test, stats_nb_test))\n",
    "sx_test_zt, training_norm = normalize(sx_test, training_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppoi_hat = model.predict(sx_test_zt)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(ppoi_exact, '-o', label='exact')\n",
    "plt.plot(phat_rej[:, 0], '-o', label='rejection abc')\n",
    "plt.plot(phat_smc[:, 0], '-o', label='SMC abc')\n",
    "plt.plot(ppoi_hat, '-o', label='Density abc')\n",
    "plt.legend(fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(ppoi_exact - phat_rej[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(ppoi_exact - phat_smc[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(ppoi_exact - ppoi_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.vstack((stats_poi_test, stats_nb_test))\n",
    "d = dict(x_test=xtest, sx_test=test_set, x=x, sx=sx, \n",
    "         ppoi_exact=ppoi_exact, ppoi_hat=ppoi_hat, \n",
    "         ppoi_smc=phat_smc[:, 0], ppoi_rej=phat_rej[:, 0], \n",
    "         prior_probs=prior_probs, \n",
    "         post_probs_mean_hat=post_probs_mean_de, \n",
    "         post_probs_mean_smc=post_probs_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = time_stamp + '_modelposterior_comparison_exact_DE_SMC_ns{}_ntest{}.p'.format(sample_size, ntest)\n",
    "with open(os.path.join('../data', fn), 'wb') as outfile: \n",
    "    pickle.dump(d, outfile, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
