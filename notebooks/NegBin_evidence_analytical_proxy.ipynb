{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.integrate import dblquad\n",
    "\n",
    "\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "mpl.rcParams['axes.titlesize'] = 20\n",
    "mpl.rcParams['axes.labelsize'] = 17\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['legend.fontsize'] = 16\n",
    "mpl.rcParams['figure.figsize'] = (15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the analytical evidence of the Negative Binomial model by numerical integration\n",
    "\n",
    "We generate data from the Negative Binomial model by sampling from a mixture of Poisson and Gamma distribution: \n",
    "\n",
    "\\begin{align}\n",
    "x | k, \\theta &\\sim Poisson(Gamma(k, \\theta)) \\\\\n",
    "p(x | k, \\theta) &= p_{Poisson}(x | \\lambda) \\; \\; p_{Gamma}(\\lambda | k, \\theta)\n",
    "\\end{align}\n",
    "\n",
    "We have additional Gamma priors on $k$ and $\\theta$ which parameters we fix. The marginal likelihood is given by \n",
    "\n",
    "\\begin{align}\n",
    "p(x) &= \\int \\int p_{Poisson}(x | \\lambda) \\; p_{Gamma}(\\lambda | k, \\theta) \\; p(k) \\; p(\\theta) \\; dk d\\theta\n",
    "\\end{align}\n",
    "\n",
    "We approximate this integral by calculating and summing the values over a grid of $k$ and $\\theta$ values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix the priors on k and theta \n",
    "theta2 = 2.0\n",
    "k2 = 5.\n",
    "theta3 = 1.0 \n",
    "k3 = 1\n",
    "prior_k = scipy.stats.gamma(a=k2, scale=theta2)\n",
    "prior_theta = scipy.stats.gamma(a=k3, scale=theta3)\n",
    "\n",
    "# set up a grid of values around the priors \n",
    "ks = np.linspace(5., 15, 200)\n",
    "thetas = np.linspace(0.1, 3, 200)\n",
    "\n",
    "k_grid, th_grid = np.meshgrid(ks, thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate some data \n",
    "sample_size = 20\n",
    "gamma_prior = scipy.stats.gamma(a=prior_k.rvs(), scale=prior_theta.rvs())\n",
    "\n",
    "lams = np.array([gamma_prior.rvs() for i in range(sample_size)])\n",
    "x = np.array([scipy.stats.poisson.rvs(mu=lams[i]) for i in range(sample_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nb_evidence_integrant(k, theta, x, lams, sample_size):\n",
    "    pk = prior_k.pdf(k)\n",
    "    ptheta = prior_theta.pdf(theta)\n",
    "\n",
    "    gamma_prior = scipy.stats.gamma(a=k, scale=theta)\n",
    "    value = 0.\n",
    "    for i in range(sample_size):         \n",
    "        value += np.log(scipy.stats.poisson.pmf(k=x[i], mu=lams[i]) * gamma_prior.pdf(x=lams[i]))\n",
    "\n",
    "    value = np.exp(value) * pk * ptheta\n",
    "    return value\n",
    "\n",
    "def nb_integrant_direct(k, theta, x, sample_size): \n",
    "    pk = prior_k.pdf(k)\n",
    "    ptheta = prior_theta.pdf(theta)\n",
    "    \n",
    "    r = k \n",
    "    p = theta / (1 + theta)\n",
    "    \n",
    "    value = 0\n",
    "    for i in range(sample_size): \n",
    "        value += np.log(scipy.stats.nbinom.pmf(k=x[i], n=r, p=p))\n",
    "\n",
    "    value = np.exp(value) * pk * ptheta\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nb_evidence_integral(x, lambs, prior_k, prior_theta, ks, thetas, log=False):\n",
    "    sample_size = x.size\n",
    "    \n",
    "    k_grid, th_grid = np.meshgrid(ks, thetas)\n",
    "    \n",
    "    grid_values = np.zeros((thetas.size, ks.size))\n",
    "\n",
    "    for i in range(thetas.shape[0]): \n",
    "        for j in range(ks.shape[0]): \n",
    "\n",
    "            grid_values[i, j] = nb_evidence_integrant(k_grid[i, j], th_grid[i, j], x, lams, sample_size)\n",
    "            \n",
    "    integral = np.trapz(np.trapz(grid_values, x=thetas, axis=0), x=ks, axis=0)\n",
    "    \n",
    "    return np.log(integral) if log else integral\n",
    "    \n",
    "def nb_evidence_integrant(k, theta, x, lams, sample_size):\n",
    "    pk = prior_k.pdf(k)\n",
    "    ptheta = prior_theta.pdf(theta)\n",
    "\n",
    "    gamma_prior = scipy.stats.gamma(a=k, scale=theta)\n",
    "    value = 0.\n",
    "    for i in range(sample_size):         \n",
    "        value += np.log(scipy.stats.poisson.pmf(k=x[i], mu=lams[i]) * gamma_prior.pdf(x=lams[i]))\n",
    "\n",
    "    value = np.exp(value) * pk * ptheta\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = nb_evidence_integral(x, lams, prior_k, prior_theta, ks, thetas)\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the same with purely analytical Poisson evidence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prior is gamma \n",
    "k1 = 5. \n",
    "theta1 = 2. \n",
    "prior = scipy.stats.gamma(a=k1, scale=theta1)\n",
    "\n",
    "# sample data \n",
    "sample_size = 20\n",
    "x = scipy.stats.poisson.rvs(mu=prior.rvs(), size=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the evidence: \n",
    "poisson_sum_evidence(x, k1, theta1, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
